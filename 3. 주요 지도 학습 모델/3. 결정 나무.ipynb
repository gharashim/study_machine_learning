{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 모델 구조와 작동 과정\n",
    "## 모델 구조\n",
    "결정 나무는 이름에서 알 수 있듯이 그 구조가 나무 구조(tree-structured)인 분류 및 회귀 모델 입니다.\n",
    "- 잎 노드를 제외한 모든 노드는 가지(branch)를 통해 두 개의 노드로 분지됨\n",
    "- 각 가지에는 노드를 분리하는 조건이 있고 각 노드에는 해당 조건을 만족하는 학습 샘플이 포함됨\n",
    "- 더 이상 분지되지 않는 최하위 노드인 잎 노드에 속한 학습 샘플을 바탕으로 라벨에 대한 예측을 수행함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 특성\n",
    "## 수직/수평 공간 분할\n",
    "결정 나무는 데이터 공간을 수직이나 수평으로만 분할하는 특성이 있습니다.\n",
    "- 각 가지에 부여된 조건의 구조가 특징 x랑 상수 c를 비교하는 x<c 의 구조이기 때문\n",
    "- 결정 나무는 데이터 공간을 비선형적으로 분리할 수 없어, 기존 특징을 변환하거나 새로운 특징을 생성해야 함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 높은 설명력\n",
    "결정 나무는 모델의 작동 과정을 IF - THEN 규칙 집합 형태로 손쉽게 설명할 수 있으며, 규칙의 근거 샘플 수와 정확도도 알 수 있습니다.\n",
    "- 이러한 설명력 덕분에 결정 나무는 대출 연체 여부 예측 등 설명력이 필요한 과제에 많이 사용함\n",
    "- 심지어는 지도 학습 과제가 아니라 특정한 이벤트의 발생 조건을 판단하는 데도 사용함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이진화\n",
    "결정 나무는 모든 종류의 특징을 이진화 합니다.\n",
    "- 연속형 특징 x에 대해서도 c보다 작거나 같은 지만 판단하므로, x를 사용한 것과 x<c 인지를 나타내는 이진형 특징을 사용한 것과 같은 효과를 냄\n",
    "- 연속형 특징이 가진 정보가 거의 무시된다는 문제가 있음\n",
    "- 특징이 모두 이진화 되기 때문에 다른 모델에 비해 전처리가 가장 적게 필요함\n",
    "  - 스케일링 전에는 x<c라는 조건이 스케일링 후에는 x' < c' 로 스케일만 바뀌므로 스케일링할 필요가 없음\n",
    "  - 더미화를 하지 않더라도 x == c라는 형태의 조건을 통해 더미화를 한 것처럼 모델이 작동함\n",
    "  - 결측을 따로 대체하지 않더라도 결측 자체를 값으로 간주하여 x == nan 이라는 형태의 질문을 만들 수도 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 주요 하이퍼 파라미터\n",
    "## 깊이\n",
    "깊이가 깊어질수록 가지가 더 많아 데이터 공간이 더 잘게 쪼개지므로, 깊이와 복잡도는 정비례한다고 할 수 있습니다.\n",
    "- 결정 나무의 모델 복잡도는 깊이로 결정된다고 하더라도 과언이 아님\n",
    "- 사이킷런에는 max_depth, min_samples_leaf, min_impurity_decrease 등 복잡도와 관련된 다양한 하이퍼 파라미터가 있으나 모두 깊이를 결정하기 위한 것임"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스 가중치\n",
    "클래스 가중치를 설정함으로써 비용 민감 모델로 변환할 수 있음\n",
    "\n",
    "$\\hat{y}=\n",
    "\\begin{cases}\n",
    "1,\\;if\\;w_1n_1>w_0n_0\\\\\n",
    "0,\\;\\;\\,otherwise\n",
    "\\end{cases}$\n",
    "\n",
    "- $w_1$ : $n_1$에 대한 가중치 (보통 클래스 불균형 비율로 설정)\n",
    "- $w_0$ : $n_0$에 대한 가중치 (보통 1로 설정)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분지 기준\n",
    "분기 기준에 따른 모델의 성능은 큰 차이가 없다고 알려져 있습니다.\n",
    "- 결정 나무의 학습은 각 노드의 불순도(impurity)를 최소화하는 조건을 찾아 노드를 분지하는 것이라 할 수 있음\n",
    "- 불순도란 각 노드에 속한 라벨의 편차라고 할 수 있음\n",
    "  - (분류) 라벨이 한 클래스의 값을 주로 가질 때 불순도가 낮음\n",
    "  - (회귀) 라벨의 표준편차가 작을 때 불순도가 낮음\n",
    "- 불순도를 측정하는 척도로 엔트로피와 지니 지수 등이 있으니, 측정 방법에 따른 모델의 성능은 큰 차이가 없다고 알려져 있음\n",
    "  - 대표적인 하이퍼 파라미터지만 측정 방법에 따른 성능 차이가 크지 않아 하이퍼 파라미터 튜닝 대상에 포함할 필요가 없음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 사이킷런 실습\n",
    "## 예제 데이터 불러오기\n",
    "결정 나무를 학습할 예제 데이터를 불어 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../data/classification/glass6.csv')\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2022)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "결정 나무는 tree 모듈의 DecisionTreeClassifier와 DecisionTreeRegressor 클래스를 이용해 구현할 수 있습니다.\n",
    "\n",
    "주요 인자\n",
    "- max_depth\n",
    "  - 최대 깊이\n",
    "  - 기본값 : None\n",
    "    - 기본값으로 설정되면 잎 노드에 min_samples_split보다 작은 샘플 수가 포함될 때까지 분지하여 최대 깊이까지 학습합니다.\n",
    "- min_samples_split\n",
    "  - 노드를 분지할 수 있는 노드 내 최소 샘플 수\n",
    "  - 기본값: 2\n",
    "- class_weight\n",
    "  - 클래스 가중치로 키가 클래스 값이 가중치인 사전\n",
    "  - 기본값 : None\n",
    "    - 기본값으로 설정되면 각 클래스에 대한 가중치를 모두 1로 설정합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정 나무 모델 학습 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.metrics import *\n",
    "model = DTC(random_state=2022).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "print(acc, rec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인3 : 결정 나무를 분지할 때 모든 조건을 탐색하지 않고 임의로 일부만 탐색하므로 실행시마다 결과가 달라질 수 있습니다. 이를 방지하기 위해서 씨드를 고정했습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리의 불필요 확인\n",
    "앞서 설명한대로 스케일링할 필요가 없는지를 확인해보겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리의 불필요성 확인 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "Z_train = scaler.transform(X_train)\n",
    "Z_test = scaler.transform(X_test)\n",
    "model2 = DTC(random_state=2022).fit(Z_train, y_train)\n",
    "y_pred = model2.predict(Z_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "print(acc,rec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스 가중치 설정\n",
    "클래스 가중치를 설정해서 비용 민감 모델을 학습하겠습니다\n",
    "\n",
    "클래스 불균형 비율 계산 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.352941176470589\n"
     ]
    }
   ],
   "source": [
    "num_majority_sample = y_train.value_counts().iloc[0]\n",
    "num_minority_sample = y_train.value_counts().iloc[-1]\n",
    "class_imbalance_ratio = num_majority_sample / num_minority_sample\n",
    "print(class_imbalance_ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 1\n",
    "  - value_counts 메서드를 이용해 다수 클래스 샘플 수를 계산합니다. \n",
    "  - value_counts 메서드는 시리즈 요소의 출현 빈도를 내림차순으로 정렬하므로 0번째에 나오는 값이 다수 클래스의 샘풀 수가 됩니다.\n",
    "  \n",
    "\n",
    "- 라인 2\n",
    "  - 라인 1과 비슷한 방법으로 소수 클래스 샘플 수를 계산 했습니다.\n",
    "\n",
    "- 라인 3\n",
    "  - 다수 클래스 샘플 수를 소수 클래스 샘플 수로 나눠 클래스 불균형 비율을 계산"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 가중치 적용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "model3 = DTC(random_state=2022, class_weight={0:1,1:class_imbalance_ratio}).fit(X_train, y_train)\n",
    "y_pred = model3.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "print(acc, rec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 1\n",
    "  - 클래스 0의 가중치를 1로, 클래스 1의 가중치를 class_imbalance_ratio로 설정\n",
    "\n",
    "\n",
    "- 성능에 전혀 변화가 없음\n",
    "- 가중치를 더 크게 부여해야 함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 가중치를 설정해서 비용 민감 모델을 학습하겠습니다.\n",
    "\n",
    "클래스 가중치 적용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9259259259259259 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "model4 = DTC(class_weight={0:1,1:class_imbalance_ratio*100}).fit(X_train, y_train)\n",
    "y_pred = model4.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "rec = recall_score(y_test,y_pred)\n",
    "print(acc, rec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 재현율과 정확도가 모두 올랐음\n",
    "- 이는 소수 클래스의 결정 공간이 확장할 때 주로 발생하는 다수 클래스의 오 뷴류가 발생하지 않았기 때문\n",
    "- 그러나 일반적으로는 소수 클래스에 대한 가중치를 크게 설정할수록 정확도는 떨어지고 재현율은 올라감"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "107109ef1f3d2c1d8ef2422d7f3c7553b0305ed5b701a76fbc5bdcb10e21ee2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
