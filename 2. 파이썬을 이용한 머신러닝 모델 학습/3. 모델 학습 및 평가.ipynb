{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 사이킷런을 이용한 모델 학습\n",
    "## 지도 학습 모델\n",
    "사이킷런은 다양한 지도 학습 모델 클래스를 지원하며, 모든 클래스의 사용 과정이 거의 비슷합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](images/model.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 데이터 불러오기\n",
    "모델 학습에 사용할 예제 데이터를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 데이터 불러오기\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.chdir('../../data')\n",
    "df1 = pd.read_csv('classification/sonar.csv')\n",
    "df2 = pd.read_csv('classification/iris.csv')\n",
    "df3 = pd.read_csv('regression/wankara.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df1.drop('y', axis=1)\n",
    "y1 = df1['y']\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state = 2022)\n",
    "\n",
    "\n",
    "X2 = df2.drop('y', axis=1)\n",
    "y2 = df2['y']\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state = 2022)\n",
    "\n",
    "\n",
    "X3 = df3.drop('y', axis=1)\n",
    "y3 = df3['y']\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, random_state = 2022)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- df1: 이진 분류 데이터\n",
    "- df2: 다중 분류 데이터\n",
    "- df3: 회귀 데이터"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 인스턴스화\n",
    "모델 인스턴스화는 사이킷런의 지도 학습 클래스를 이용해 인스턴스를 만드는 것을 의미 합니다. 이 과정에서 모델의 하이퍼 파라미터를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=10)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스화 예시 : 최대 깊이가 10인 결정 나무 모델\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "model = DTC(max_depth=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=10)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스화 예시 : 사전을 이용한 입력\n",
    "parameter = {'max_depth' : 10}\n",
    "model = DTC(**parameter)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 클래스(DecisionTreeClassifier)와 설정한 하이퍼 파라미터 (max_depth=10)만 출력됨\n",
    "- 이렇게 만든 인스턴스는 하이퍼 파라미터를 통해 어떻게 학습할지만 설정됐고 아직 학습되지 않았으므로 예측과 학습된 모델 정보 확인 등을 할 수 없음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 인스턴스화는 사이킷런의 지도 학습 클래스를 이용해 인스턴스를 만드는 것을 의미 합니다. 이 과정에서 모델의 하이퍼 파라미터를 설정 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류 모델, 다중 분류 모델, 회귀 모델 생성\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "\n",
    "model1 = DTC(max_depth=10)\n",
    "model2 = DTC(max_depth=10)\n",
    "model3 = DTR(max_depth=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit 메서드\n",
    "fit 메서드는 특징과 라벨 간 관계를 학습하며, fit 메서드를 사용한 다음에 모델을 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 인스턴스화 예시 : 최대 깊이가 10인 결정 나무 모델\n",
    "model1.fit(X1_train, y1_train)\n",
    "model2.fit(X2_train, y2_train)\n",
    "model3.fit(X3_train, y3_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 사이킷런을 이용한 모델 평가\n",
    "## predict 메서드\n",
    "predict 메서드는 학습한 모델을 사용해 새로 입력된 특징 벡터의 라벨을 예측 합니다. 이때 새로 입력된 데이터의 구조는 학습 데이터의 구조와 반드시 같아야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict 메서드 예시\n",
    "y1_pred = model1.predict(X1_test)\n",
    "y2_pred = model2.predict(X2_test)\n",
    "y3_pred = model3.predict(X3_test)\n",
    "\n",
    "display(y1_pred[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict는 예측한 라벨을 ndarray로 반환하며 이 배열의 각 요소는 같은 위치에 있는 X1_test의 요소에 대한 예측 결과로, y_pred1[i]는 X1_test[i]를 예측한 결과임"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict_proba 메서드\n",
    "predict_proba 메서드는 각 샘플이 특정 클래스에 속할 확률을 계산 합니다. 출력은 ndarray로 i행 j열 요소는 i번째 샘플이 j번째 클래스에 속할 확률을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict 메서드 예시\n",
    "y1_prob = model1.predict_proba(X1_test)\n",
    "y2_prob = model2.predict_proba(X2_test)\n",
    "\n",
    "display(y2_prob[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict는 예측한 라벨을 ndarray로 반환하며 이 배열의 각 요소는 같은 위치에 있는 X1_test의 요소에 대한 예측 결과로, y_pred1[i]는 X1_test[i]를 예측한 결과임"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이진 분류 모델 평가\n",
    "분류 모델을 평가하는 데 사용하는 함수로는 metrics 모듈의 accurac_socre, precision_score, recall_score, f1_score 등이 있습니다. 이 모듈에 속한 모든 평가 함수는 순서대로 실제 라벨과 예측한 레발을 입력 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7884615384615384 0.7083333333333334 0.8095238095238095 0.7555555555555556\n"
     ]
    }
   ],
   "source": [
    "# 이진 분류 모델 평가 예시\n",
    "from sklearn.metrics import *\n",
    "\n",
    "acc = accuracy_score(y1_test, y1_pred)\n",
    "pre = precision_score(y1_test, y1_pred)\n",
    "rec = recall_score(y1_test, y1_pred)\n",
    "f1 = f1_score(y1_test, y1_pred)\n",
    "print(acc, pre, rec, f1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 분류 모델 평가\n",
    "다중 분류 모델은 average 인자를 'micro', 'macro', 'weighted' 등으로 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rkfka\\Desktop\\강의자료 (수강생 제공)-20221203T140147Z-001\\강의자료 (수강생 제공)\\내가 만든 코드\\2. 파이썬을 이용한 머신러닝 모델 학습\\3. 모델 학습 및 평가.ipynb 셀 23\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rkfka/Desktop/%EA%B0%95%EC%9D%98%EC%9E%90%EB%A3%8C%20%28%EC%88%98%EA%B0%95%EC%83%9D%20%EC%A0%9C%EA%B3%B5%29-20221203T140147Z-001/%EA%B0%95%EC%9D%98%EC%9E%90%EB%A3%8C%20%28%EC%88%98%EA%B0%95%EC%83%9D%20%EC%A0%9C%EA%B3%B5%29/%EB%82%B4%EA%B0%80%20%EB%A7%8C%EB%93%A0%20%EC%BD%94%EB%93%9C/2.%20%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EB%AA%A8%EB%8D%B8%20%ED%95%99%EC%8A%B5/3.%20%EB%AA%A8%EB%8D%B8%20%ED%95%99%EC%8A%B5%20%EB%B0%8F%20%ED%8F%89%EA%B0%80.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 잘못된 다중 분류 모델 평가 예시\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rkfka/Desktop/%EA%B0%95%EC%9D%98%EC%9E%90%EB%A3%8C%20%28%EC%88%98%EA%B0%95%EC%83%9D%20%EC%A0%9C%EA%B3%B5%29-20221203T140147Z-001/%EA%B0%95%EC%9D%98%EC%9E%90%EB%A3%8C%20%28%EC%88%98%EA%B0%95%EC%83%9D%20%EC%A0%9C%EA%B3%B5%29/%EB%82%B4%EA%B0%80%20%EB%A7%8C%EB%93%A0%20%EC%BD%94%EB%93%9C/2.%20%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EB%AA%A8%EB%8D%B8%20%ED%95%99%EC%8A%B5/3.%20%EB%AA%A8%EB%8D%B8%20%ED%95%99%EC%8A%B5%20%EB%B0%8F%20%ED%8F%89%EA%B0%80.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m f1_score(y2_test, y2_pred)\n",
      "File \u001b[1;32mc:\\Users\\rkfka\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1136\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[0;32m   1002\u001b[0m     y_true,\n\u001b[0;32m   1003\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1010\u001b[0m ):\n\u001b[0;32m   1011\u001b[0m     \u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \n\u001b[0;32m   1013\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1136\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1137\u001b[0m         y_true,\n\u001b[0;32m   1138\u001b[0m         y_pred,\n\u001b[0;32m   1139\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1140\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1141\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1142\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1143\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1144\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rkfka\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1277\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[0;32m   1149\u001b[0m     y_true,\n\u001b[0;32m   1150\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1158\u001b[0m ):\n\u001b[0;32m   1159\u001b[0m     \u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \n\u001b[0;32m   1161\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1277\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1278\u001b[0m         y_true,\n\u001b[0;32m   1279\u001b[0m         y_pred,\n\u001b[0;32m   1280\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1281\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1282\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1283\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1284\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1285\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1286\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1287\u001b[0m     )\n\u001b[0;32m   1288\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\rkfka\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1563\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1562\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1563\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1565\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rkfka\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1381\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1379\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1380\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1381\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1382\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1384\u001b[0m         )\n\u001b[0;32m   1385\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[0;32m   1386\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1387\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# 잘못된 다중 분류 모델 평가 예시\n",
    "f1_score(y2_test, y2_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 분류 모델은 average 인자를 'micro', 'macro', 'weighted' 등으로 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 다중 분류 모델 평가 예시\n",
    "macro_f1 = f1_score(y2_test, y2_pred, average='macro')\n",
    "micro_f1 = f1_score(y2_test, y2_pred, average='micro')\n",
    "\n",
    "print(macro_f1, micro_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 모델 평가\n",
    "MAE와 MSE는 각각 metrics 모듈의 mean_absolute_error와 mean_squared_error 함수로 계산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5113670374677841 3.6639055358127717 1.9141331029509865\n"
     ]
    }
   ],
   "source": [
    "# 회귀 모델 평가 예시\n",
    "mae = mean_absolute_error(y3_test, y3_pred)\n",
    "mse = mean_squared_error(y3_test, y3_pred)\n",
    "\n",
    "rmse = mse**0.5\n",
    "\n",
    "print(mae, mse, rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "107109ef1f3d2c1d8ef2422d7f3c7553b0305ed5b701a76fbc5bdcb10e21ee2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
