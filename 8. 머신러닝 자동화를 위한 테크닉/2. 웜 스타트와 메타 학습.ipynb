{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 메타 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웜 스타트란?\n",
    "- 탐색 알고리즘 대부분은 임의로 설정한 초깃값부터 탐색을 시작하며, 초깂값에 따라 탐색 시간과 성능이 좌우됨\n",
    "- 웜 스타트는 적절한 초깃값을 설정하여 탐색을 시작하는 것으로, 탐색 시간을 줄이고 좋은 성능의 해를 찾는 것을 도와줌"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메타 모델을 활용한 웜 스타트\n",
    "- 메타 학습이란 데이터에 관한 데이터인 메타 데이터(meta data)로 모델을 학습하는 것을 의미하며, 이렇게 학습한 모델을 메타 모델이라고 합니다.\n",
    "- 메타 모델은 데이터와 모델 정보를 입력하면 예상되는 성능을 반환합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자주 사용하는 메타 특징\n",
    "- 머신러닝 자동화 시스템에서 주로 사용하는 메타 특징은 다음과 같습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자주 사용하는 메타 특징\n",
    "\n",
    "|특징|설명|특징|설명|\n",
    "|---|---|---|---|\n",
    "|샘플 개수|데이터에 포함된 샘플 개수|수치형 특징 개수|데이터에 포함된 수치형 특징 개수|\n",
    "|특징 개수|데이터에 포함된 특징 개수|범주형 특징 개수|데이터에 포함된 범주형 특징 개수|\n",
    "|클래스 대비 특징 비율|특징 개수 / 클래스 개수|수치형 특징 비율|수치형 특징 개수 / 특징 개수|\n",
    "|클래스 비율 분포|예) 각 클래스 비율의 최댓값, 각 클래스 비율의 최솟값|범주형 특징 비율|범주형 특징 개수 / 특징 개수|\n",
    "|연속형 라벨의 분포|예) 라벨의 범위, 라벨의 평균, 라벨의 표준편차|특징 간 상관관계 분포|특징 간 상관관계의 최댓값, 최솟값 등|\n",
    "|샘플 대비 특징 비율|특징 개수 / 샘플 개수| | |\n",
    "\n",
    "- 클래스 비율 분포와 특징 간 상관관계 분포를 통해 분포를 요약하는 통계량(예: 평균, 최댓값 등)을 메타 특징으로 사용함을 알 수 있음\n",
    "- 예를 들어, 두 측징 X1과 X2 간 상관관계가 아니라 가능한 두 특징 간 상관관계의 통계량을 사용함\n",
    "- 그 이유는 데이터마다 특징 개수, 클래스 개수 등이 다르므로, 각 특징 및 클래스에 대한 값을 메타 특징으로 사용하면 데이터마다 메타 특징 개수가 달라지기 때문\n",
    "\n",
    "어느 데이터에 대해서나 동일하게 추출할 수 있고 모델 성능에 영향을 끼치는 메타 특징을 정의하는 것이 중요함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메타 모델의 종류\n",
    "- 어떠한 지도 학습 모델도 메타 모델로 사용할 수 있지만, 적은 데이터로도 학습이 잘되고 특징의 중요도를 반영할 수 있는 모델이 좋습니다.\n",
    "- 메타 모델 요구 사항\n",
    " - 일바적으로 메타 모델은 데이터 확보가 어려우므로 적은 데이터로 학습하더라도 잘 작동해야 함\n",
    " - 메타 특징, 모델, 하이퍼 파라미터의 중요도를 조절할 수 있어야 함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 실습 1- 데이터 준비"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메타 데이터 준비\n",
    "- autoMPG8.csv 데이터로 신경망의 하이퍼 파라미터를 튜닝할 때 초깃값을 설정하기 위한 메타 학습을 해보겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메타 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = '../data/regression/'\n",
    "meta_file_list = [  'abalone.csv',\n",
    "                    'autoMPG6.csv',\n",
    "                    'baseball.csv',\n",
    "                    'friedman.csv',\n",
    "                    'stock.csv',\n",
    "                    'wankara.csv']\n",
    "\n",
    "meta_data_list = []\n",
    "for file in meta_file_list:\n",
    "    df = pd.read_csv(data_path + '/' + file)\n",
    "    X = df.drop('y', axis = 1)\n",
    "    y = df['y']\n",
    "    meta_data_list.append((X, y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 11~15: meta_file_list에 정의된 파일 이름을 순회하면서 데이터를 불러오고 특징과 라벨로 분리한 뒤 튜플 형태로 meta_data_list에 추가합니다. 즉, meta_data_list[i][0]은 i번째 데이터의 특징 벡터를, meta_data_list[i][1]은 i번째 데이터의 라벨을 나타냅니다.\n",
    "\n",
    "실제로는 머신러닝 자동화 시스템이 구축돼 새로운 데이터가 끊임없이 들어올 때만 혹은 들어올 것이라 예상될 때만 메타 학습을 사용하며, 한 데이터에 대해서만 메타 모델을 적용하는 것은 매우 비효율적임"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메타 특징 추출\n",
    "- 메타 특징을 추출하는 함수를 작성하겠습니다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메타 특징 추출 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta_features(X, y):\n",
    "    num_samples, num_features = X.shape\n",
    "    label_max = y.max()\n",
    "    label_min = y.min()\n",
    "    label_mean = y.mean()\n",
    "    label_std = y.std()\n",
    "    corr_mean = X.corr().abs().values.mean()\n",
    "    corr_max = X.corr().abs().values.max()\n",
    "    corr_min = X.corr().abs().values.min()\n",
    "\n",
    "    meta_features = [   num_samples,\n",
    "                        num_features,\n",
    "                        label_max,\n",
    "                        label_min,\n",
    "                        label_mean,\n",
    "                        label_std,\n",
    "                        corr_mean,\n",
    "                        corr_max,\n",
    "                        corr_min]\n",
    "    \n",
    "    return meta_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2: shape 메서드를 이용해 X의 행 개수와 열 개수를 각각 num_samples와 num_features에 저장합니다.\n",
    "- 라인 3~6: y의 최댓값, 최솟값, 평균, 표준편차를 각각 label_max, label_min, label_mean, label_std에 저장합니다.\n",
    "- 라인 7~9: 특징 간 상관관계의 절댓값의 평균, 최댓값, 최솟값을 각각 corr_mean, corr_max, corr_min에 저장합니다. 이때 데이터프레임의 집계 메서드를 사용하면 열별 통계량을 반환하므로 ndarray로 변환 후에 집계 메서드를 사욯했습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 데이터로부터 메타 특징을 추출하겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메타 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = []\n",
    "for X, y in meta_data_list:\n",
    "    meta_features = extract_meta_features(X, y)\n",
    "    meta_data.append(meta_features)\n",
    "\n",
    "meta_col_names = [  'num_samples',\n",
    "                    'num_features',\n",
    "                    'label_max',\n",
    "                    'label_min',\n",
    "                    'label_mean',\n",
    "                    'label_std',\n",
    "                    'corr_mean',\n",
    "                    'corr_max',\n",
    "                    'corr_min']\n",
    "\n",
    "meta_data = pd.DataFrame(meta_data, columns = meta_col_names)\n",
    "meta_data['data_name'] = meta_file_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2~4: meta_data_list에 속한 X와 y로부터 메타 특징을 추출하고 그 값을 meta_data에 추가합니다.\n",
    "- 라인 17: 각 데이터 이름을 나타내는 data_name 칼럼을 추가합니다. 이 칼럼은 하이퍼 파라미터 튜닝 결과 데이터와 병합하겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메타 데이터 생성\n",
    "- 하이퍼 파라미터를 샘플링하는 함수를 다음과 같이 작성하겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼 파라미터 샘플러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def hyperparameter_sampling():\n",
    "    h1 = np.random.randint(5, 15)\n",
    "    h2, h3, h4 = np.random.randint(0, 10, 3)\n",
    "    if h2 == 0:\n",
    "        h3, h4 = 0, 0\n",
    "    elif h3 == 0:\n",
    "        h4 = 0\n",
    "    max_iter = np.random.choice([100, 200, 1000, 2000])\n",
    "    random_state = np.random.choice([2020, 2021, 2022])\n",
    "    return h1, h2, h3, h4, max_iter, random_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 3: 첫 번째 은닉층에 포함될 노드 수 h1을 5와 15 사이에서 임의로 샘플링합니다. 첫 번째 은닉층에 포함될 녿는 0보다 커야 하므로 따로 샘플링했습니다.\n",
    "- 라인 4: 두 번째, 세 번째, 네 번째 은닉층에 포함될 노드 수 h2, h3, h4를 0부터 10 사이에서 임의로 샘플링합니다.\n",
    "- 라인 5~6: 두 번째 은닉층에 포함될 노드 수가 0이면 세 번째와 네 번째에 포함될 노드 수도 0으로 설정합니다.\n",
    "- 라인 7~8: 세 번째 은닉층에 포함될 노드 수가 0이면 네 번째에 포함될 노드 수도 0으로 설정합니다.\n",
    "- 라인 9: 최대 이터레이션 횟수 max_iter를 100, 20, 1000, 2000 중 하나로 설정합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터마다 1,000 번씩 하이퍼 파라미터를 샘플링하고 그 때의 성능을 experiment_data에 저장하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor as MLP\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "experiment_data = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 5: 코드 실행 과정을 출력하기 위해 tqdm 함수를 불러왔습니다.\n",
    "- 라인 6: 불필요한 경고가 뜨는 것을 방지했습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터마다 1,000번씩 하이퍼 파라미터를 샘플링하고 그때의 성능을 experiment_data에 저장하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abalone.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [7:59:13<00:00, 28.75s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoMPG6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:21:07<00:00,  4.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseball.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:12:06<00:00,  7.93s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friedman.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [4:00:06<00:00, 14.41s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:54:46<00:00, 10.49s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wankara.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [3:32:56<00:00, 12.78s/it] \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(meta_data_list)):\n",
    "    data_name = meta_file_list[i]\n",
    "    X, y = meta_data_list[i]\n",
    "    print(data_name)\n",
    "    for j in tqdm(range(1000)):\n",
    "        h1, h2, h3, h4, max_iter, random_state = hyperparameter_sampling()\n",
    "        if h2 == 0:\n",
    "            layers = (h1, )\n",
    "        elif h3 == 0:\n",
    "            layers = (h1, h2)\n",
    "        elif h4 == 0:\n",
    "            layers = (h1, h2, h3)\n",
    "        else:\n",
    "            layers = (h1, h2, h3, h4)\n",
    "        \n",
    "        model = MLP(    hidden_layer_sizes = layers,\n",
    "                        max_iter = max_iter,\n",
    "                        random_state = random_state )\n",
    "        score_list = - cross_val_score(model, X, y, cv = 5,\n",
    "                                    scoring = 'neg_mean_absolute_error')\n",
    "        score = score_list.mean()\n",
    "        record = [data_name, h1, h2, h3, h4, max_iter, random_state, score]\n",
    "        experiment_data.append(record)\n",
    "\n",
    "hyper_param_cols = ['h1', 'h2', 'h3', 'h4', 'max_iter', 'random_state']\n",
    "experiment_data = pd.DataFrame(experiment_data,\n",
    "                                columns = ['data_name'] + hyper_param_cols + ['score'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 8~10: range(meta_data_list)를 순회하는 방식으로 meta_file_list와 meta_data_list를 순회합니다.\n",
    "- 라인 11~12: 코드 실행 기간이 기므로, data_name을 출력하고 tqdm을 사용해 진행률을 출력합니다.\n",
    "- 라인 13: hyperparameter_sampling 함수를 사용해 h1, h2, h3, h4, max_iter, random_state를 샘플링합니다.\n",
    "- 라인 14~21: h2, h3, h4의 값에 따라 layers를 설정합니다. 예를 들어, h2가 0 이라면 layers를 (h1,)으로, h3가 0이라면 layers를 (h1, h2)로 설정합니다.\n",
    "- 라인 23~30: 샘플링한 하이퍼 파라미터를 갖는 신경망을 k-겹 교차 검증을 통해 평가합니다. 또, 그 결과를 record에 추가하고 record를 experiment_data에 추가합니다.\n",
    "- 라인 32~34: experiment_data를 데이터프레임으로 변환합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta_data에 experiment_data를 부착하여 meta_data를 완성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_name</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2000</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.552002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.587305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.574452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.584702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.572927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>wankara.csv</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2021</td>\n",
       "      <td>48.130159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>wankara.csv</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.144957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>wankara.csv</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.100776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>wankara.csv</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.042856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>wankara.csv</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>2021</td>\n",
       "      <td>41.274367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        data_name  h1  h2  h3  h4  max_iter  random_state      score\n",
       "0     abalone.csv  13   1   2   9      2000          2021   1.552002\n",
       "1     abalone.csv  10   6   4   2       200          2022   1.587305\n",
       "2     abalone.csv   9   7   4   9       200          2021   1.574452\n",
       "3     abalone.csv   9   1   4   0      1000          2022   1.584702\n",
       "4     abalone.csv  14   1   5   0       200          2021   1.572927\n",
       "...           ...  ..  ..  ..  ..       ...           ...        ...\n",
       "5995  wankara.csv   6   8   4   2       100          2021  48.130159\n",
       "5996  wankara.csv  14   7   7   0      1000          2020   1.144957\n",
       "5997  wankara.csv   8   4   2   3      1000          2021   1.100776\n",
       "5998  wankara.csv   8   6   9   7      1000          2022   1.042856\n",
       "5999  wankara.csv   7   9   3   2      1000          2021  41.274367\n",
       "\n",
       "[6000 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_features</th>\n",
       "      <th>label_max</th>\n",
       "      <th>label_min</th>\n",
       "      <th>label_mean</th>\n",
       "      <th>label_std</th>\n",
       "      <th>corr_mean</th>\n",
       "      <th>corr_max</th>\n",
       "      <th>corr_min</th>\n",
       "      <th>data_name</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4176</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.931034</td>\n",
       "      <td>3.220003</td>\n",
       "      <td>0.807719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.418048</td>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2000</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.552002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4176</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.931034</td>\n",
       "      <td>3.220003</td>\n",
       "      <td>0.807719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.418048</td>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.587305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4176</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.931034</td>\n",
       "      <td>3.220003</td>\n",
       "      <td>0.807719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.418048</td>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.574452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4176</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.931034</td>\n",
       "      <td>3.220003</td>\n",
       "      <td>0.807719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.418048</td>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.584702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4176</td>\n",
       "      <td>8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.931034</td>\n",
       "      <td>3.220003</td>\n",
       "      <td>0.807719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.418048</td>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.572927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_samples  num_features  label_max  label_min  label_mean  label_std  \\\n",
       "0         4176             8       29.0        1.0    9.931034   3.220003   \n",
       "1         4176             8       29.0        1.0    9.931034   3.220003   \n",
       "2         4176             8       29.0        1.0    9.931034   3.220003   \n",
       "3         4176             8       29.0        1.0    9.931034   3.220003   \n",
       "4         4176             8       29.0        1.0    9.931034   3.220003   \n",
       "\n",
       "   corr_mean  corr_max  corr_min    data_name  h1  h2  h3  h4  max_iter  \\\n",
       "0   0.807719       1.0  0.418048  abalone.csv  13   1   2   9      2000   \n",
       "1   0.807719       1.0  0.418048  abalone.csv  10   6   4   2       200   \n",
       "2   0.807719       1.0  0.418048  abalone.csv   9   7   4   9       200   \n",
       "3   0.807719       1.0  0.418048  abalone.csv   9   1   4   0      1000   \n",
       "4   0.807719       1.0  0.418048  abalone.csv  14   1   5   0       200   \n",
       "\n",
       "   random_state     score  \n",
       "0          2021  1.552002  \n",
       "1          2022  1.587305  \n",
       "2          2021  1.574452  \n",
       "3          2022  1.584702  \n",
       "4          2021  1.572927  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_data = pd.merge(   meta_data,\n",
    "                        experiment_data,\n",
    "                        on = 'data_name')\n",
    "display(meta_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 실습 2- 메타 모델 학습 및 활용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메테 모델 학습\n",
    "- 메타 모델로 k-최근접 이웃 모델을 사용하겠습니다. 하이퍼 파라미터 튜닝은 따로 하지 않았습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메타 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "meta_X = meta_data.drop(['data_name', 'score'], axis = 1)\n",
    "meta_X['random_state_2020'] = (meta_X['random_state'] == 2020).astype(int)\n",
    "meta_X['random_state_2021'] = (meta_X['random_state'] == 2021).astype(int)\n",
    "# meta_X = meta_X.drop(['random_state'], axis = 1)\n",
    "meta_y = meta_data['score']\n",
    "scaler = MinMaxScaler().fit(meta_X)\n",
    "meta_X = scaler.transform(meta_X)\n",
    "meta_model = KNN().fit(meta_X, meta_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 3: meta_data에서 특징으로 활용할 수 없는 data_name과 score를 제거합니다.\n",
    "- 라인 4~6: random_state는 범주형 변수이므로 범주화합니다. 이 변수만 범주형 변수이므로 직접 더미화를 했습니다.\n",
    "- 라인 8~9: meta_X를 0과 1 사이로 스케일링합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메타 모델 활용\n",
    "- 새로 입력된 데이터 autoMPG8.csv에 대해 메타 모델을 사용해서 초깃값을 설정하겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메타 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + '/autoMPG8.csv')\n",
    "X = df.drop('y', axis = 1)\n",
    "y = df['y']\n",
    "meta_features = extract_meta_features(X, y)\n",
    "sample_list = []\n",
    "for _ in range(100):\n",
    "    h1, h2, h3, h4, max_iter, random_state = hyperparameter_sampling()\n",
    "    if h2 == 0:\n",
    "        layers = (h1, )\n",
    "    elif h3 == 0:\n",
    "        layers = (h1, h2)\n",
    "    elif h4 == 0:\n",
    "        layers = (h1, h2, h3)\n",
    "    else:\n",
    "        layers = (h1, h2, h3, h4)\n",
    "    sample_list.append(meta_features + [h1, h2, h3, h4, max_iter, random_state])\n",
    "\n",
    "sample_list = pd.DataFrame( sample_list,\n",
    "                            columns = meta_col_names + hyper_param_cols)\n",
    "\n",
    "sample_list['random_state_2020'] = (sample_list['random_state'] == 2020).astype(int)\n",
    "sample_list['random_state_2021'] = (sample_list['random_state'] == 2021).astype(int)\n",
    "# sample_list = sample_list.drop(['random_state'], axis = 1)\n",
    "y_pred = meta_model.predict(scaler.transform(sample_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_features</th>\n",
       "      <th>label_max</th>\n",
       "      <th>label_min</th>\n",
       "      <th>label_mean</th>\n",
       "      <th>label_std</th>\n",
       "      <th>corr_mean</th>\n",
       "      <th>corr_max</th>\n",
       "      <th>corr_min</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>random_state</th>\n",
       "      <th>random_state_2020</th>\n",
       "      <th>random_state_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>392</td>\n",
       "      <td>7</td>\n",
       "      <td>46.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.445918</td>\n",
       "      <td>7.805007</td>\n",
       "      <td>0.628158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181528</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>392</td>\n",
       "      <td>7</td>\n",
       "      <td>46.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.445918</td>\n",
       "      <td>7.805007</td>\n",
       "      <td>0.628158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181528</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>392</td>\n",
       "      <td>7</td>\n",
       "      <td>46.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.445918</td>\n",
       "      <td>7.805007</td>\n",
       "      <td>0.628158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181528</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_samples  num_features  label_max  label_min  label_mean  label_std  \\\n",
       "93          392             7       46.6        9.0   23.445918   7.805007   \n",
       "10          392             7       46.6        9.0   23.445918   7.805007   \n",
       "16          392             7       46.6        9.0   23.445918   7.805007   \n",
       "\n",
       "    corr_mean  corr_max  corr_min  h1  h2  h3  h4  max_iter  random_state  \\\n",
       "93   0.628158       1.0  0.181528   9   9   3   8      2000          2020   \n",
       "10   0.628158       1.0  0.181528  10   1   5   8      2000          2021   \n",
       "16   0.628158       1.0  0.181528   7   2   3   5      1000          2021   \n",
       "\n",
       "    random_state_2020  random_state_2021  \n",
       "93                  1                  0  \n",
       "10                  0                  1  \n",
       "16                  0                  1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_sample = sample_list.loc[np.argsort(y_pred)[:3]]\n",
    "display(init_sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메타 모델 검증\n",
    "- sample_list에 속한 값의 라벨인 y_actual을 계산하여 비교해보겠습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메타 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10,    7,    3,    3,  200, 2020])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list.values[0][-8:-2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = []\n",
    "for sample in sample_list.values:\n",
    "    h1, h2, h3, h4, max_iter, random_state = sample[-8:-2].astype(int)\n",
    "    if h2 == 0:\n",
    "        layers = (h1, )\n",
    "    elif h3 == 0:\n",
    "        layers = (h1, h2)\n",
    "    elif h4 == 0:\n",
    "        layers = (h1, h2, h3)\n",
    "    else:\n",
    "        layers = (h1, h2, h3, h4)\n",
    "    \n",
    "    model = MLP(    hidden_layer_sizes = layers,\n",
    "                    max_iter = max_iter,\n",
    "                    random_state = random_state)\n",
    "    \n",
    "    score_list = - cross_val_score( model, X, y, cv = 5,\n",
    "                                    scoring = 'neg_mean_absolute_error')\n",
    "    \n",
    "    score = score_list.mean()\n",
    "    y_actual.append(score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2~3: sample_list에 있는 요소를 sample로 순회하면서 하이퍼 파라미터와 관련된 부분만 입력 받습니다. 왜냐하면 새로운 데이터의 메타 특징은 하나여서 샘플링할 때마다 바뀌지 않으므로 학습에 전혀 도움이 되지 않기 때문입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_actual과 y_pred 간의 스피어만 상관계수(Spearman correlation coefficient)를 계산해보겠습니다. 스피어만 상관계수는 두 변수의 순위 간 상관관계를 나타내는 지표로 두 변수의 스케일에 영향을 받지 않습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메타 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.5320988061794312, pvalue=1.2174355643464018e-08)\n",
      "[21. 41. 16.]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, rankdata\n",
    "print(spearmanr(y_actual, y_pred))\n",
    "print(rankdata(y_actual)[np.argsort(y_pred)[:3]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2: y_actual과 y_pred 간 스피엄나 상관계수를 계산합니다.\n",
    "- 라인 3: 메타 모델이 MAE가 가장 작으리라 예측한 세 개이 해가 실제 평가 결과에서 몇 위를 차지하는지를 출력합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측값과 실제값 간 스피어만 상관계수가 0.6191로, 두 변수 간 양의 상관관계가 존재함.\n",
    "- 또한, 예측 결과에서 1등 부터 3등 까지라고 판단한 세 개의 샘플은 실제로는 13등, 26등, 7등으로, 다소 아쉽기는 하지만 사용하기 어려운 수준은 아님"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb3e04fb40beff7675317d1c1c8fb49eb61db4a7ae559ce0ef4a250a17faaf57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
