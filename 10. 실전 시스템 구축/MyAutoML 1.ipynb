{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 파트에서는 지금까지 학습한 내용을 바탕으로 머신러닝 자동화 시스템을 구축해보겠습니다.\n",
    "|시스템명|과제 유형|범위|활용 방법론|\n",
    "|---|---|---|---|\n",
    "|MyAutoML1|분류|모델 선택과 하이퍼파라미터 튜닝|그리드 서치|\n",
    "|MyAutoML2|회귀|모델 선택과 하이퍼파라미터 튜닝|실험 <br> 랜덤 서치|\n",
    "|MyAutoML3|이진 분류|모델 선택과 하이퍼파라미터 튜닝 <br> 스케일링 <br> 재샘플링 <br> 스태킹 앙상블|메타 모델 <br> 베이지안 최적화|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 문제 정의 및 클래스 설계"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 탐색 공간\n",
    "MyAutoml_1은 탐색 공간 내 모든 분류 모델과 하이퍼파라미터를 비교함으로써 최적의 분류 모델과 하이퍼파라미터를 탐색합니다. 여기서 사용자가 탐색하지 않을 모델을 고를 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td>모델</td>\n",
    "    <td>하이퍼 파라미터</td>\n",
    "    <td>탐색 공간</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">k-최근접 이웃<br>(KNeighborsClassfier)</td>\n",
    "    <td>n_neighbors</td>\n",
    "    <td>{3, 5, 7, 9, 11}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>metric</td>\n",
    "    <td>{'euclidean', 'manhattan'}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">결정 나무<br>(DecisionTreeClassifier)</td>\n",
    "    <td>max_depth</td>\n",
    "    <td>{3, 5, 7, 9}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>min_samples_split</td>\n",
    "    <td>{2, 5, 10}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"3\">랜덤 포레스트<br>(RandomForestClassfier)</td>\n",
    "    <td>n_estimators</td>\n",
    "    <td>{50, 100, 200}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>max_depth</td>\n",
    "    <td>{2, 3, 4}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>max_features</td>\n",
    "    <td>{0.2, 0.4, 0.6, 0.8, 1.0}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">신경망<br>(MLPClassfier)</td>\n",
    "    <td>hidden_layer_sizes</td>\n",
    "    <td>{(10,), (10, 10), (20, 20), (15, 15, 15), (20, 20, 20), (15, 15, 15, 15), (30, 30, 30, 30)}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>max_iter</td>\n",
    "    <td>{2000}</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스 설계: 인자 정의\n",
    "MyAutoml_1은 다음과 같은 인자를 갖는 파이썬 클래스로 개발합니다.\n",
    "|인자|설명|기본값|\n",
    "|---|---|---|\n",
    "|exclude_modlels|탐색에서 제외할 모델 목록<br>['KNN', 'DT', 'RF', 'MLP']의 부분 집합|[ ]|\n",
    "|seed|k-최근접 이웃을 제외한 각 모델의 시드|2022|\n",
    "|cv|폴드 개수|5|\n",
    "|scoring|분류 평가 척도|'accracy|\n",
    "|summarize_score|평가 결과 요약 방법|'mean'|\n",
    "|early_stopping|교차 검증에서의 조기 종료 여부|False|\n",
    "|early_stopping_criteria|조기 종료 기준으로 다음을 만족하면 조기 종료를 수행<br><br>1 - (현재 폴드에서의 성능 / 현재까지 가장 좋은 모델의 성능) > early_stopping_criteria|0.1|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클래스 설계: 메서드 정의\n",
    "MyAutoml_1은 다음과 같은 메서드를 갖습니다.\n",
    "|메서드|설명|\n",
    "|---|---|\n",
    "|fit|특징 X와 라벨 y를 입력받아 그리드 서치를 사용해 모델과 하이퍼파라미터를 탐색합니다. 한, 최고 점수의 모델 인스턴스를 전체 데이터로 재학습해 model 속성에 저장합니다.|\n",
    "|show_leaderboard|모델 및 파라미터 탐색 결과인 리더보드를 출력합니다. 이때 리더보드는 모델, 하이퍼파라미터, 성능 지표로 구성된 데이터프레임 입니다.|\n",
    "|predict|fit 메서드에서 저장한 model로 새로 입력된 특징의 라벨을 예측합니다.|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 시스템 구현"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈 불러오기\n",
    "시스템 구현에 필요한 모듈과 함수를 다음고 같이 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import *\n",
    "from functools import partial\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 8: functools.partial은 인자가 기본값이 아닌 값으로 설정된 함수를 변수에 저장하는 데 사용합니다. 여기서는 average 인자가 'macro'와 'weighted'로 설정해야 하는 다중 쿨래스 분류 평가 지표를 정의하는데 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoML1:\n",
    "    ## 생성자 : 클래스의 생성자의 인자를 정의 합니다.\n",
    "    def __init__(\n",
    "        self,\n",
    "        exclude_models = [],\n",
    "        seed = None,\n",
    "        cv = 5,\n",
    "        scoring = 'accuracy',\n",
    "        summarize_scoring = 'mean',\n",
    "        early_stopping = False,\n",
    "        early_stopping_criteria = 0.1,\n",
    "    ):\n",
    "        # self.exclude_models 정의\n",
    "        model_set = {'KNN', 'DT', 'RF', 'MLP'} # 입력할 수 있는 전체 모델 목록인 model_set를 집합 자료형으로 정의\n",
    "        if set(exclude_models) == model_set:\n",
    "            raise ValueError('모든 모델을 제외할 수 없습니다.') # exclude_models와 model_set이 같으면 모든 모델이 탐색 대상에서 제외 / raise는 의도적으로 오류를 발생시키는 데 사용\n",
    "        improper_models = set(exclude_models) - model_set # exclude_models에는 포햄됐으나, model_set에는 포함되지 않은 집합을 improper_models라고 정의\n",
    "        if len(improper_models) >= 1:\n",
    "            raise ValueError(\n",
    "                '{}는 exclude_models에 포함할 수 없습니다.'.format(improper_models)\n",
    "            ) # improper_models에 한 개의 요소라도 포함되면 오류를 발생\n",
    "        self.exclude_models = exclude_models # exclude_models를 self.exclude_models에 저장합니다.\n",
    "\n",
    "        # self.seed 정의\n",
    "        if(type(seed) != int) and (seed is not None):\n",
    "            raise ValueError('seed는 int형 혹은 None 이어야 합니다.') # seed는 int 자료형 혹은 None 이어야 하므로 seed가 int 자료형이나 None이 아니라면 오류를 발생 시킨다.\n",
    "        self.seed = seed\n",
    "\n",
    "        # self.cv 정의\n",
    "        if type(cv) != int:\n",
    "            raise ValueError('cv는 int 형이어야 합니다.')\n",
    "        if cv < 2:\n",
    "            raise ValueError('cv는 2보다는 커야 합니다.') # k-겹 교차 검증에서 폴드의 개수를 나타내는 cv는 2 이상의 자연수여야 한다. 따라서 int 자료형이 아니거나 2보다 작은 값이라면 오류를 발생 시킨다.\n",
    "        self.cv = cv\n",
    "\n",
    "        # self.scoring 정의\n",
    "        scoring_dict = {\n",
    "            'accuracy': accuracy_score,\n",
    "            'precision': precision_score,\n",
    "            'weighted-precision': partial(precision_score, average = 'weighted'),\n",
    "            'macro-precision': partial(precision_score, average = 'macro'),\n",
    "            'recall': recall_score,\n",
    "            'weighted-recall': partial(recall_score, average = 'weighted'),\n",
    "            'macro-recall': partial(recall_score, average = 'macro'),\n",
    "            'f1': f1_score,\n",
    "            'weighted-f1': partial(f1_score, average = 'weighted'),\n",
    "            'macro-f1': partial(f1_score, average = 'macro')\n",
    "        } # 사용자가 입력한 문자열을 대응되는 함수로 바꾸기 위한 사전 자료형인 scoring_dict를 정의\n",
    "\n",
    "        if scoring not in scoring_dict.keys():\n",
    "            msg = 'scoring은 {} 중 하나여야 합니다.'.format(scoring_dict.keys())\n",
    "            raise ValueError(msg) # 입력한 scoring이 scoring_dict의 키가 아니면 오류를 발생시킵니다.\n",
    "        self.scoring = scoring_dict[scoring] # scoring_dict를 scoring으로 인덱싱한 함수를 self.scoring에 저장합니다.\n",
    "\n",
    "        #self.summarize 정의\n",
    "        summarize_scoring_dict = {'mean': np.mean, 'max': np.max, 'min': np.min} # 사용자가 입력한 문자열을 대응되는 함수로 바꾸기 위한 사전 자료형 / 최소, 평균, 최대 중 하나로 k-겹 교차 검증 결과 요약\n",
    "\n",
    "        if summarize_scoring not in ['mean', 'max', 'min']:\n",
    "            msg = 'summarize_scoring는 {\"mean\", \"max\", \"min\"}중 하나여야 합니다.'\n",
    "            raise ValueError(msg)\n",
    "        self.summarize_scoring = summarize_scoring_dict[summarize_scoring]\n",
    "\n",
    "        #self.early_stopping 정의\n",
    "        if type(early_stopping) is not bool:\n",
    "            raise ValueError('early_stopping은 True 혹은 False여야 합니다.') # early_stopping은 부율 자료형 / 다른 자료형 입력 시 오류 발생\n",
    "        self.early_stopping = early_stopping\n",
    "\n",
    "        #early_stopping_criteria 정의\n",
    "        if type(early_stopping_criteria) is not float:\n",
    "            raise ValueError('early_stopping_criteria 자료형은 float이어야 합니다.')\n",
    "        if early_stopping_criteria <= 0 or early_stopping_criteria >= 1:\n",
    "            raise ValueError('early_stopping_criteria는 0과 1 사이의 값이어야 합니다.') # early_stopping_criteria는 0과 1 사이의 float 자료형 / 그 외의 값 오류 발생\n",
    "        self.early_stopping_criteria = early_stopping_criteria\n",
    "\n",
    "    ## fit 메서드\n",
    "    def fit(self, X, y):\n",
    "        # X, y 포맷 변경\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values # X가 데이터프레임이라면 values 속성을 사용해 X를 ndarray로 변환 / 여기서 instance(instance, class)는 instance가 class의 객체이면 True를, 그렇지 않으면 False 반환\n",
    "        elif isinstance(X, list) or isinstance(X, tuple):\n",
    "            X = np.array(X) # X가 리스트 혹은 튜플이라면 np.array 함수를 사용해 ndarray로 변환\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        elif isinstance(y, list) or isinstance(y, tuple):\n",
    "            y = np.array(y)\n",
    "        # K최근접 이웃 그리드 정의\n",
    "        kNN_grid = ParameterGrid(\n",
    "            {'n_neighbors': [3, 5, 7, 9, 11], 'metric': ['euclidean', 'manhattan']}\n",
    "        )\n",
    "        #결정 나무 그리드 정의\n",
    "        DT_grid = ParameterGrid(\n",
    "            {'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10]}\n",
    "        )\n",
    "        # 랜덤 포레스트 그리드 정의\n",
    "        RFR_grid = ParameterGrid(\n",
    "            {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [2, 3, 4],\n",
    "                'max_features': [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "            }\n",
    "        )\n",
    "        # 신경망 그리드 정의\n",
    "        MLP_grid = ParameterGrid(\n",
    "            {\n",
    "                'hidden_layer_sizes': [\n",
    "                    (10,),\n",
    "                    (10, 10),\n",
    "                    (20, 20),\n",
    "                    (15, 15, 15),\n",
    "                    (20, 20, 20),\n",
    "                    (15, 15, 15, 15),\n",
    "                    (30, 30, 30, 30),\n",
    "                ],\n",
    "                'max_iter': [2000]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 전체 그리드 정의\n",
    "        grid = {\n",
    "            KNeighborsClassifier : kNN_grid,\n",
    "            DecisionTreeClassifier: DT_grid,\n",
    "            RandomForestClassifier: RFR_grid,\n",
    "            MLPClassifier: MLP_grid\n",
    "        }\n",
    "\n",
    "        # 그리드 서치 시작\n",
    "        best_score = 0 # 현재 까지 찾은 최고의 점수를 0으로 초기화\n",
    "        self.leaderboard = [] # 리더보드 속성을 빈 리스트로 초기화 / 그리드 서치를 수행하면서 이 리스트에 탐색 결과 추가 / 마지막에 데이터 프레임으로 변환 예정\n",
    "        for model_func in grid.keys(): # 분류 모델 클래스를 model_func으로 순회합니다.\n",
    "            if model_func in self.exclude_models:\n",
    "                continue # model_func이 exclude_models에 속하면 탐색하지 않습니다.\n",
    "            for params in grid[model_func]: # model_func의 그리드를 params로 순회합니다.\n",
    "                if model_func != KNeighborsClassifier:\n",
    "                    params['random_state'] = self.seed # model_func이 kNeighborsClassifier가 아니라면 사전인 params에 {'random_state': self.seed}를 추가 / k-최근접 이웃은 random_state 인자가 없으므로 추가 x\n",
    "                kf = KFold(n_splits = self.cv, shuffle = True, random_state = self.seed) # self.cv와 self.seed를 이용해 KFold 인스턴스를 정의\n",
    "                fold_score_list = [] # 각 모델과 하이퍼 파라미터 교차 검증 결과 담을 fold_score_list를 빈 리스트로 초기화\n",
    "                # 조기 종료를 하는 경우\n",
    "                if self.early_stopping:\n",
    "                    for train_index, test_index in kf.split(X):\n",
    "                        X_train, X_test = X[train_index], X[test_index]\n",
    "                        y_train, y_test = y[train_index], y[test_index]\n",
    "                        model = model_func(**params).fit(X_train, y_train)\n",
    "                        y_pred = model.predict(X_test) # kf로 구분한 train_index, test_index를 사용해 학습 데이터와 평가 데이터 정의, 학습, 예측 수행\n",
    "                        fold_score = self.scoring(y_test, y_pred)\n",
    "                        fold_score_list.append(fold_score) # self.scoring을 사용해 y_test와 y_pred를 비교한 결과를 fold_score에 저장하고 이를 fold_score_list에 추가합니다.\n",
    "                        if fold_score < best_score * (1 - self.early_stopping_criteria):\n",
    "                            break # fold_score가 현재까지 최고 점수보다 self.early_stopping_criteria * 100% 이상 낮다면 조기 종료 합니다.\n",
    "                # 조기 종료를 하지 않는 경우\n",
    "                else:\n",
    "                    for train_index, test_index in kf.split(X):\n",
    "                        X_train, X_test = X[train_index], X[test_index]\n",
    "                        y_train, y_test = y[train_index], y[test_index]\n",
    "                        model = model_func(**params).fit(X_train, y_train)\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        fold_score = self.scoring(y_test, y_pred)\n",
    "                        fold_score_list.append(fold_score) # self.early_stoopping이 False라면 조기 종료하지 않고 모델과 하이퍼 파라미터를 평가합니다.\n",
    "                # 현재까지 찾은 최고의 해 및 리더보드 업데이트\n",
    "                score = self.summarize_scoring(fold_score_list) # self.summarizing_scoring을 이용해 fold_score_list를 대푯값으로 요약\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_model_func = model_func\n",
    "                    best_params = params # 현재까지 찾은 해보다 현재 찾은 해가 더 좋은 해라면 best_score, best_model_func, best_params를 업데이트\n",
    "                self.leaderboard.append([model_func, params, score]) # 현재 해 정보를 self.leaderboard에 추가합니다.\n",
    "        self.model = best_model_func(**best_params).fit(X, y) # 최종 모델과 하이퍼 파라미터를 갖는 모델을 전체 데잍에 대해 재학습합니다.\n",
    "        self.leaderboard = pd.DataFrame(self.leaderboard,\n",
    "                                            columns = ['모델', '파라미터', '점수']) # self.leaderboard를 모델, 파라미터, 점수라는 칼럼을 갖는 데이터프레임으로 변환\n",
    "\n",
    "    ## predict 메서드\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    ## show_leaderboard 메서드\n",
    "    def show_leaderboard(self):\n",
    "        return self.leaderboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 시스템 활용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활용 예제 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../data/classification/winequality-red.csv')\n",
    "X = df.drop('y', axis = 1)\n",
    "y = df['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>모델</th>\n",
       "      <th>파라미터</th>\n",
       "      <th>점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;class 'sklearn.tree._classes.DecisionTreeClas...</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 10, 'ran...</td>\n",
       "      <td>0.609753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.8, 'n_estim...</td>\n",
       "      <td>0.604761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.604753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.604120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 1.0, 'n_estim...</td>\n",
       "      <td>0.603482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;class 'sklearn.neighbors._classification.KNei...</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 3}</td>\n",
       "      <td>0.500915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;class 'sklearn.neighbors._classification.KNei...</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 9}</td>\n",
       "      <td>0.500315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;class 'sklearn.neighbors._classification.KNei...</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 5}</td>\n",
       "      <td>0.499052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;class 'sklearn.neighbors._classification.KNei...</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 7}</td>\n",
       "      <td>0.496589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;class 'sklearn.neighbors._classification.KNei...</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 11}</td>\n",
       "      <td>0.494690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   모델  \\\n",
       "18  <class 'sklearn.tree._classes.DecisionTreeClas...   \n",
       "63  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "55  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "53  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "65  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "..                                                ...   \n",
       "0   <class 'sklearn.neighbors._classification.KNei...   \n",
       "3   <class 'sklearn.neighbors._classification.KNei...   \n",
       "1   <class 'sklearn.neighbors._classification.KNei...   \n",
       "2   <class 'sklearn.neighbors._classification.KNei...   \n",
       "4   <class 'sklearn.neighbors._classification.KNei...   \n",
       "\n",
       "                                                 파라미터        점수  \n",
       "18  {'max_depth': 7, 'min_samples_split': 10, 'ran...  0.609753  \n",
       "63  {'max_depth': 4, 'max_features': 0.8, 'n_estim...  0.604761  \n",
       "55  {'max_depth': 4, 'max_features': 0.4, 'n_estim...  0.604753  \n",
       "53  {'max_depth': 4, 'max_features': 0.2, 'n_estim...  0.604120  \n",
       "65  {'max_depth': 4, 'max_features': 1.0, 'n_estim...  0.603482  \n",
       "..                                                ...       ...  \n",
       "0           {'metric': 'euclidean', 'n_neighbors': 3}  0.500915  \n",
       "3           {'metric': 'euclidean', 'n_neighbors': 9}  0.500315  \n",
       "1           {'metric': 'euclidean', 'n_neighbors': 5}  0.499052  \n",
       "2           {'metric': 'euclidean', 'n_neighbors': 7}  0.496589  \n",
       "4          {'metric': 'euclidean', 'n_neighbors': 11}  0.494690  \n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aml = MyAutoML1()\n",
    "aml.fit(X, y)\n",
    "result = aml.show_leaderboard()\n",
    "display(result.sort_values(by = '점수', ascending = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활용 예제 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "df = pd.read_csv('../data/classification/bupa.csv')\n",
    "X = df.drop('y', axis = 1)\n",
    "y = df['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 자동화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>모델</th>\n",
       "      <th>파라미터</th>\n",
       "      <th>점수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.803900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.799603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.6, 'n_estim...</td>\n",
       "      <td>0.794762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 0.2, 'n_estim...</td>\n",
       "      <td>0.788789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 0.4, 'n_estim...</td>\n",
       "      <td>0.787954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;class 'sklearn.tree._classes.DecisionTreeClas...</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10, 'ran...</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>&lt;class 'sklearn.neural_network._multilayer_per...</td>\n",
       "      <td>{'hidden_layer_sizes': (15, 15, 15), 'max_iter...</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;class 'sklearn.neighbors._classification.KNei...</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 11}</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>&lt;class 'sklearn.neural_network._multilayer_per...</td>\n",
       "      <td>{'hidden_layer_sizes': (15, 15, 15, 15), 'max_...</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;class 'sklearn.tree._classes.DecisionTreeClas...</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 2, 'rand...</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   모델  \\\n",
       "54  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "58  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "59  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "37  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "55  <class 'sklearn.ensemble._forest.RandomForestC...   \n",
       "..                                                ...   \n",
       "15  <class 'sklearn.tree._classes.DecisionTreeClas...   \n",
       "70  <class 'sklearn.neural_network._multilayer_per...   \n",
       "4   <class 'sklearn.neighbors._classification.KNei...   \n",
       "72  <class 'sklearn.neural_network._multilayer_per...   \n",
       "19  <class 'sklearn.tree._classes.DecisionTreeClas...   \n",
       "\n",
       "                                                 파라미터        점수  \n",
       "54  {'max_depth': 4, 'max_features': 0.2, 'n_estim...  0.803900  \n",
       "58  {'max_depth': 4, 'max_features': 0.6, 'n_estim...  0.799603  \n",
       "59  {'max_depth': 4, 'max_features': 0.6, 'n_estim...  0.794762  \n",
       "37  {'max_depth': 3, 'max_features': 0.2, 'n_estim...  0.788789  \n",
       "55  {'max_depth': 4, 'max_features': 0.4, 'n_estim...  0.787954  \n",
       "..                                                ...       ...  \n",
       "15  {'max_depth': 5, 'min_samples_split': 10, 'ran...  0.641026  \n",
       "70  {'hidden_layer_sizes': (15, 15, 15), 'max_iter...  0.617647  \n",
       "4          {'metric': 'euclidean', 'n_neighbors': 11}  0.615385  \n",
       "72  {'hidden_layer_sizes': (15, 15, 15, 15), 'max_...  0.605263  \n",
       "19  {'max_depth': 9, 'min_samples_split': 2, 'rand...  0.558824  \n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rkfka\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aml = MyAutoML1(scoring = 'f1', early_stopping = True, early_stopping_criteria = 0.05)\n",
    "aml.fit(X, y)\n",
    "result = aml.show_leaderboard()\n",
    "display(result.sort_values(by = '점수', ascending = False))\n",
    "display(aml.predict(X)[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "107109ef1f3d2c1d8ef2422d7f3c7553b0305ed5b701a76fbc5bdcb10e21ee2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
