{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 랜덤 서치 개요\n",
    "## 랜덤 서치란?\n",
    "랜덤 서치는 이름 그대로 탐색 공간에 있는 해를 임의로 선택해서 탐색하는 방법입니다. 어느 문제에나 손쉽게 적용할 수 있다는 장점 덕분에, 하이퍼파라미터 튜닝뿐만 아니라 많은 최적화 문제를 해결하는 데 자주 사용합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률적 샘플링\n",
    "확률적 샘플링이란 특정한 확률 분포를 따르는 확률 변수로부터 값을 추출하는 것을 의미합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이산형 확률 분포\n",
    "(1) 유니폼 분포\n",
    "- 이산 유니폼 분포란 주사위를 던졌을 때 윗면에 나오는 숫자의 분포처럼 상태 공간의 크기가 유한하고 상태 공간의 각 값의 출현 확률이 같은 분포를 의미합니다.\n",
    "\n",
    "(2) 푸아송 분포\n",
    "- 푸아송 분포(Poisson distribution)는 단위 시간 안에 어떤 사건이 몇 번 발생할지를 나타내는 이산 확률 분포로, 범주형 변수가 특정 구간의 값을 주로 갖는 상황에서 자주 사용합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연속형 확률 분포\n",
    "(1) 유니폼 분포\n",
    "- 연속 유니폼 분포란 주사위를 던졌을 때 특정 구간에 속하는 값의 출현 확률이 같은 분포를 의미합니다.\n",
    "\n",
    "(2) 로그 유니폼 분포\n",
    "- 로그 유니폼 분포는 계수 페널티의 가중치 처럼 범위가 매우 넓고 특정 값보다 크면 값 간 차이가 무의미한 변수에 대해 가정하기에 적절한 분포입니다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플링 함수\n",
    "(1) np.choice\n",
    "- 넘파이의 random.choice 함수를 사용하면 배열에서 하나의 값을 임의로 선택할 수 있으며, 이는 이산 유니폼 분포로부터 샘플링하는 것과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = [1,2,3,4,5]\n",
    "s = np.random.choice(X)\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) scipy.stats 모듈\n",
    "- scipy.stats 모듈에 속한 클래스를 사용하면 특정한 확률 분포를 따르는 확률 변수 인스턴스를 생성할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 클래스\n",
    "- 범주형\n",
    "    - 베르누이 분포 : bernouli\n",
    "    - 이항 분포 : binom\n",
    "    - 푸아송 분포 : poisson\n",
    "- 연속형\n",
    "    - 지수 분포 : expon\n",
    "    - 유니폼 분포 : uniform\n",
    "    - 로그 유니폼 분포 : loguniform\n",
    "    - 정규 분포 : normal\n",
    "\n",
    "이들 클래스는 rvs라는 메서드를 이용해 샘플링할 수 있으며, 이 메서드는 생성할 샘플 수를 입력으로 받습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipy.stats 모듈에 속한 클래스를 사용하면 특정한 확률 분포를 따르는 확률 변수 인스턴스를 생성할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "푸아송 분포 샘플링 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 13 11 11  6]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "poisson_rv = poisson(10) # 파라미터를 10으로 설정\n",
    "X = poisson_rv.rvs(5) # 샘플 5개 샘플링\n",
    "print(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유니폼 및 로그 유니폼 분포 샘플링 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.52768967 13.83532981 10.43740088 13.61561673 12.51747384 17.49374222\n",
      " 12.97913828 16.96162034 17.87910666 15.35953274]\n",
      "[1446.90166344   65.6394865    56.84012777   12.34251628 2541.68612836\n",
      "   12.03003979   25.06488075   34.37277079   68.24522984 8238.39232335]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform, loguniform\n",
    "uni_rv = uniform(10, 10) # 하한 (첫 인자) = 10, 상한 (첫 인자 + 두 번째 인자) = 10 + 10\n",
    "log_uni_rv = loguniform(10, 10000) # 하한 = 10, 상한 = 10000\n",
    "X1 = uni_rv.rvs(10)\n",
    "X2 = log_uni_rv.rvs(10)\n",
    "\n",
    "print(X1)\n",
    "print(X2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RandomSearchCV를 이용한 랜덤 서치\n",
    "## 예제 데이터 불러오기\n",
    "랜덤 서치를 실습할 데이터를 불러옵니다. 이때, k-겹 교차 검증을 사용해 해를 평가할 예정이므로 train_test_split으로 학습 데이터와 평가 데이터로\n",
    "분리하지는 않았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/classification/movement_libras.csv')\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSerachCV 클래스\n",
    "RandomSearchCV 클래스는 랜덤 서치 방식으로 하이퍼 파라미터를 튜닝합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 인자\n",
    "- estimator\n",
    "    - 분류 및 회귀 모델 인스턴스\n",
    "- param_distribution\n",
    "    - 하이퍼파라미터의 분포(자료형: 사전)\n",
    "- cv\n",
    "    - 폴드 개수\n",
    "- scoring\n",
    "    - 평가 척도\n",
    "- n_iter\n",
    "    - 평가 횟수\n",
    "- refit\n",
    "    - 가장 좋은 성능의 하이퍼파라미터를 갖는 모델을 전체 데이터로 재학습할지 여부\n",
    "\n",
    "param_distribution의 키는 estimator의 인자이고 값은 해당 인자가 따르는 확률 분포임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = {\n",
    "    'max_features':loguniform(0.5, 1),\n",
    "    'max_depth': range(3, 8),\n",
    "    'criterion':['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 서치\n",
    "RandomSearchCV를 이용해 랜덤 포레스트의 하이퍼파라미터를 튜닝해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>0.786111</td>\n",
       "      <td>4.906395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>2.973703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>1.856940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.697222</td>\n",
       "      <td>5.149861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 6, 'max_...</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>4.459257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'max_fea...</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>1.715420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'max_fea...</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>1.252883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_fea...</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>1.200715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'max_fea...</td>\n",
       "      <td>0.697222</td>\n",
       "      <td>0.960854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>4.336323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'criterion': 'entropy', 'max_depth': 7, 'max_...         0.786111   \n",
       "1  {'criterion': 'entropy', 'max_depth': 4, 'max_...         0.677778   \n",
       "2  {'criterion': 'gini', 'max_depth': 5, 'max_fea...         0.736111   \n",
       "3  {'criterion': 'entropy', 'max_depth': 4, 'max_...         0.697222   \n",
       "4  {'criterion': 'entropy', 'max_depth': 6, 'max_...         0.783333   \n",
       "5  {'criterion': 'gini', 'max_depth': 6, 'max_fea...         0.758333   \n",
       "6  {'criterion': 'gini', 'max_depth': 3, 'max_fea...         0.597222   \n",
       "7  {'criterion': 'gini', 'max_depth': 5, 'max_fea...         0.736111   \n",
       "8  {'criterion': 'gini', 'max_depth': 4, 'max_fea...         0.697222   \n",
       "9  {'criterion': 'entropy', 'max_depth': 4, 'max_...         0.683333   \n",
       "\n",
       "   mean_fit_time  \n",
       "0       4.906395  \n",
       "1       2.973703  \n",
       "2       1.856940  \n",
       "3       5.149861  \n",
       "4       4.459257  \n",
       "5       1.715420  \n",
       "6       1.252883  \n",
       "7       1.200715  \n",
       "8       0.960854  \n",
       "9       4.336323  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf = RandomizedSearchCV(\n",
    "    RFC(random_state=2022),\n",
    "    dist,\n",
    "    cv=5,\n",
    "    n_iter=10,\n",
    "    scoring='accuracy',\n",
    "    random_state=2022\n",
    ").fit(X, y)\n",
    "result = pd.DataFrame(clf.cv_results_)\n",
    "display(result[['params','mean_test_score','mean_fit_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', max_depth=7,\n",
      "                       max_features=0.7066451376545405, random_state=2022)\n",
      "0.7861111111111111\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 0.7066451376545405}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 랜덤 서치 직접 구현하기\n",
    "랜덤 서치를 이용한 하이퍼파라미터 튜닝을 직접 구현해보겠습니다. 그리드 서치와 마찬가지로 직접 구현하는 것이 실무에서 사용하기에 적절합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "best_score = -1\n",
    "num_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_iter):\n",
    "    total_score = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = X.loc[train_index]\n",
    "        X_test = X.loc[test_index]\n",
    "        y_train = y.loc[train_index]\n",
    "        y_test = y.loc[test_index]\n",
    "        _max_features=loguniform(0.5, 1).rvs(1)[0]\n",
    "        _max_depth = np.random.choice(range(3, 8))\n",
    "        _criterion = np.random.choice(['gini','entropy'])\n",
    "\n",
    "        model = RFC(\n",
    "            max_features=_max_depth,\n",
    "            max_depth=_max_depth,\n",
    "            criterion=_criterion\n",
    "        ).fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        total_score += score/5\n",
    "\n",
    "if total_score > best_score:\n",
    "    best_score = total_score\n",
    "    best_parameter = [_max_features, _max_depth, _criterion]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 5~6\n",
    "    - 사용자가 지정한 num_iter 만큼 샘플링과 평가를 반복합니다.\n",
    "- 라인 8~12\n",
    "    - KFold를 이용해 k-겹 교차 검증을 수행합니다.\n",
    "- 라인 13~15\n",
    "    - max_features, max_depth, criterion을 주어진 분포 내에서 샘플링한 결과를 각각 _max_features, _max_depth, _criterion에 저장합니다. max_features는 유니폼 분포를 따르는 확률 변수로부터 하나의 값을 샘플링 했습니다. 이때 rvs(1)을 하더라도 배열로 반환되므로 [0]을 이용해 값만 가져왔습니다.\n",
    "- 라인17~19\n",
    "    - 샘플링한 값 _max_features, _max_depth, criterion을 하이퍼 파라미터로 하는 모델을 학습합니다.\n",
    "- 라인24~26\n",
    "    - 현재 탐색하는 하이퍼 파라미터를 사용 했을 때의 평가 점수가 지금까지의 최고 점수보다 크다면 best_score와 best_parameter를 업데이트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5012820636984986, 4, 'entropy'] 0.7583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(best_parameter, best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "107109ef1f3d2c1d8ef2422d7f3c7553b0305ed5b701a76fbc5bdcb10e21ee2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
