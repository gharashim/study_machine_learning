{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 최댓값 및 최솟값 탐색 알고리즘\n",
    "## 최댓값과 최솟값 탐색 알고리즘 : 필요성\n",
    "그리드 서치를 비롯한 하이퍼 파라미터 튜닝 해법 대부분은 여러 하이퍼 파라미터를 평가하고 비교해서 최적의 하이퍼 파리미터를 찾습니다. 이때, 하이퍼 파라미터와 점수를 전부 저장하면 메모리 관리 측면에서 매우 비효율적입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "탐색 결과를 활용한 최적 하이퍼 파라미터 선택 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def find_optimal_h(H, S):\n",
    "    idx = np.argmax(S)\n",
    "    return H[idx]\n",
    "\n",
    "H = [\"H1\", \"H2\", \"H3\", \"H4\", \"H5\"]\n",
    "S = [0.8, 0.7, 0.9, 0.6, 0.7]\n",
    "print(find_optimal_h(H, S))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2 : 탐색한 하이퍼 파라미터 목록 H와 점수 목록 S를 입력 받습니다.\n",
    "- 라인 3 : np.argmax 함수를 사용해 S의 최댓값의 인덱스를 idx에 저장합니다.\n",
    "- 라인 4 : S의 최댓값의 인덱스를 H의 인덱스로 사용합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최댓값과 최솟값 탐색 알고리즘 : 파이썬 구현"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최댓값 탐색 알고리즘 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_h_update(H, S):\n",
    "    current_max_value = -np.inf\n",
    "    for h, s in zip(H, S):\n",
    "        if s > current_max_value:\n",
    "            current_max_value = S\n",
    "            h_star = h\n",
    "        return h_star\n",
    "\n",
    "H = [\"H1\", \"H2\", \"H3\", \"H4\", \"H5\"]\n",
    "S = [0.8, 0.7, 0.9, 0.6, 0.7]\n",
    "print(find_optimal_h(H, S))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2 : 현재까지 찾은 최댓값을 음의 무한대로 초기화합니다.\n",
    "- 라인 3 : H와 S를 각각 h와 s로 순회 합니다.\n",
    "- 라인 4-6 : s가 current_max_value보다 크다면 current_max_value를 s로, h_star를 h로 업데이트 합니다.\n",
    "- 라인 9-11 : find_optimal_h_update를 사용해 최적의 하이퍼 파리미터를 찾습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GridSearhCV를 이용한 그리드 서치\n",
    "그리드 서치를 실습할 데이터를 불러옵니다. 이때, k-겹 교차 검증을 사용해 해를 평가할 예정이므로 train_test_split으로 학습 데이터와 평가 데이터로 분리하지는 않았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('../data/classification/optdigits.csv')\n",
    "df2 = pd.read_csv('../data/regression/baseball.csv')\n",
    "X1 = df1.drop('y', axis=1)\n",
    "y1 = df1['y']\n",
    "X2 = df2.drop('y', axis=1)\n",
    "y2 = df2['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSerachCV 클래스 : 주요 인자\n",
    "사이킷런의 model_selection_GridSearchCV 크래스를 이용하면 손쉽게 하이퍼파라미터 튜닝을 위한 그리드 서치를 구현할 수 있습니다. 이 클래스는 주어진 그리드에 속하는 모든 해를 k-겹 교차 검증 방식으로 평가하여 가장 좋은 하이퍼 파라미터를 찾습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요인자\n",
    "- estimator\n",
    "    - 분류 및 회귀 모델 인스턴스\n",
    "- param_grid\n",
    "    - 파라미터 그리드 (사전 자료형)\n",
    "- cv\n",
    "    - 폴드 개수\n",
    "- scoring\n",
    "    - 평가 척도\n",
    "- refit\n",
    "    - 가장 좋은 성능의 하이퍼 파라미터를 갖는 모델을 전체 데이터로 재학습할지 여부"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- param_gird의 키는 estimator의 인자이고 값은 해당 인자가 갖는 값으로 구성된 배열임\n",
    "    - 예시) grid = {\"n_negibors\" : [3, 5, 7], \"metric\" : {\"euclidean\", \"manhattan\"}}\n",
    "- scoring은 각 하이퍼 파라미터를 평가하는 데 사용하는 평가 척도로 'accuracy', 'f1', 'neg_mean_absolute_error' 와 같이 문자열로 입력함. 여기서 neg_mean_absolute_error는 다른 지표처럼 값이 크면 클수록 좋다고 일관되게 평가할 수 있도록 MAE에 마이너스 부호를 붙인 것에 불과함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"n_neighbors\": [3, 5, 7],\n",
    "        \"metric\":[\"euclidean\", \"manhattan\"]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSerachCV 클래스 : 주요 메서드 및 속성\n",
    "\n",
    "주요 메서드 및 속성\n",
    "- fit\n",
    "    - 입력한 그리드 내의 모든 하이퍼 파라미터를 평가\n",
    "- predict\n",
    "    - 가장 우수한 하이퍼 파라미터를 갖는 모델로 예측을 수행\n",
    "- cv_results_\n",
    "    - 그리드 서치를 이용한 탐색 결과\n",
    "- best_estimator_\n",
    "    - 점수가 가장 높은 모델 인스턴스\n",
    "- best_score_\n",
    "    - 최고 점수\n",
    "- best_params_\n",
    "    - 점수가 가장 높은 하이퍼 파라미터"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그리드 서치\n",
    "GridSearchCV를 이용해 k-최근접 이웃(분류)의 하이퍼 파라미터를 튜닝 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 3}</td>\n",
       "      <td>0.982918</td>\n",
       "      <td>0.012592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 5}</td>\n",
       "      <td>0.982562</td>\n",
       "      <td>0.013392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 7}</td>\n",
       "      <td>0.983452</td>\n",
       "      <td>0.012793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 3}</td>\n",
       "      <td>0.978470</td>\n",
       "      <td>0.011196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5}</td>\n",
       "      <td>0.978648</td>\n",
       "      <td>0.014792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 7}</td>\n",
       "      <td>0.978292</td>\n",
       "      <td>0.011797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_score  mean_fit_time\n",
       "0  {'metric': 'euclidean', 'n_neighbors': 3}         0.982918       0.012592\n",
       "1  {'metric': 'euclidean', 'n_neighbors': 5}         0.982562       0.013392\n",
       "2  {'metric': 'euclidean', 'n_neighbors': 7}         0.983452       0.012793\n",
       "3  {'metric': 'manhattan', 'n_neighbors': 3}         0.978470       0.011196\n",
       "4  {'metric': 'manhattan', 'n_neighbors': 5}         0.978648       0.014792\n",
       "5  {'metric': 'manhattan', 'n_neighbors': 7}         0.978292       0.011797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                    cv=5,\n",
    "                    param_grid=grid,\n",
    "                    scoring=\"accuracy\").fit(X1, y1)\n",
    "result = pd.DataFrame(clf.cv_results_)\n",
    "display(result[['params','mean_test_score','mean_fit_time']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- params: param_gird의 하이퍼 파라미터\n",
    "- mean_test_score : k-겹 교차 검증에서 k번 평가한 결과의 평균값\n",
    "- mean_fit_time : 평균 학습 시간"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV를 이용해 k-최근접 이웃(분류)의 하이퍼 파라미터를 튜닝해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='euclidean', n_neighbors=7)\n",
      "0.9834519572953736\n",
      "{'metric': 'euclidean', 'n_neighbors': 7}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV를 이용해 k-최근접 이웃(회귀)의 하이퍼 파라미터를 튜닝해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 3}</td>\n",
       "      <td>-666.301580</td>\n",
       "      <td>0.006798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 5}</td>\n",
       "      <td>-651.092379</td>\n",
       "      <td>0.006197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 7}</td>\n",
       "      <td>-653.397034</td>\n",
       "      <td>0.006792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 3}</td>\n",
       "      <td>-690.902253</td>\n",
       "      <td>0.005198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5}</td>\n",
       "      <td>-655.554548</td>\n",
       "      <td>0.005197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 7}</td>\n",
       "      <td>-644.461514</td>\n",
       "      <td>0.006797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_score  mean_fit_time\n",
       "0  {'metric': 'euclidean', 'n_neighbors': 3}      -666.301580       0.006798\n",
       "1  {'metric': 'euclidean', 'n_neighbors': 5}      -651.092379       0.006197\n",
       "2  {'metric': 'euclidean', 'n_neighbors': 7}      -653.397034       0.006792\n",
       "3  {'metric': 'manhattan', 'n_neighbors': 3}      -690.902253       0.005198\n",
       "4  {'metric': 'manhattan', 'n_neighbors': 5}      -655.554548       0.005197\n",
       "5  {'metric': 'manhattan', 'n_neighbors': 7}      -644.461514       0.006797"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "clf = GridSearchCV(estimator=KNeighborsRegressor(),\n",
    "                    cv=5,\n",
    "                    param_grid=grid,\n",
    "                    scoring=\"neg_mean_absolute_error\").fit(X2, y2)\n",
    "result = pd.DataFrame(clf.cv_results_)\n",
    "display(result[['params','mean_test_score','mean_fit_time']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neg_mean_absoulte_error는 MAE에 마이너스 부호만 붙인 것임\n",
    "- mean_test_score가 -644.461514로 가장 큰 5번 행의 파라미터가 가장 좋다고 할 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "107109ef1f3d2c1d8ef2422d7f3c7553b0305ed5b701a76fbc5bdcb10e21ee2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
