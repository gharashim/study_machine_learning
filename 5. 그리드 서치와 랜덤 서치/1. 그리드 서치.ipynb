{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 최댓값 및 최솟값 탐색 알고리즘\n",
    "## 최댓값과 최솟값 탐색 알고리즘 : 필요성\n",
    "그리드 서치를 비롯한 하이퍼 파라미터 튜닝 해법 대부분은 여러 하이퍼 파라미터를 평가하고 비교해서 최적의 하이퍼 파리미터를 찾습니다. 이때, 하이퍼 파라미터와 점수를 전부 저장하면 메모리 관리 측면에서 매우 비효율적입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "탐색 결과를 활용한 최적 하이퍼 파라미터 선택 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def find_optimal_h(H, S):\n",
    "    idx = np.argmax(S)\n",
    "    return H[idx]\n",
    "\n",
    "H = [\"H1\", \"H2\", \"H3\", \"H4\", \"H5\"]\n",
    "S = [0.8, 0.7, 0.9, 0.6, 0.7]\n",
    "print(find_optimal_h(H, S))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2 : 탐색한 하이퍼 파라미터 목록 H와 점수 목록 S를 입력 받습니다.\n",
    "- 라인 3 : np.argmax 함수를 사용해 S의 최댓값의 인덱스를 idx에 저장합니다.\n",
    "- 라인 4 : S의 최댓값의 인덱스를 H의 인덱스로 사용합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최댓값과 최솟값 탐색 알고리즘 : 파이썬 구현"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최댓값 탐색 알고리즘 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_h_update(H, S):\n",
    "    current_max_value = -np.inf\n",
    "    for h, s in zip(H, S):\n",
    "        if s > current_max_value:\n",
    "            current_max_value = S\n",
    "            h_star = h\n",
    "        return h_star\n",
    "\n",
    "H = [\"H1\", \"H2\", \"H3\", \"H4\", \"H5\"]\n",
    "S = [0.8, 0.7, 0.9, 0.6, 0.7]\n",
    "print(find_optimal_h(H, S))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2 : 현재까지 찾은 최댓값을 음의 무한대로 초기화합니다.\n",
    "- 라인 3 : H와 S를 각각 h와 s로 순회 합니다.\n",
    "- 라인 4-6 : s가 current_max_value보다 크다면 current_max_value를 s로, h_star를 h로 업데이트 합니다.\n",
    "- 라인 9-11 : find_optimal_h_update를 사용해 최적의 하이퍼 파리미터를 찾습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GridSearhCV를 이용한 그리드 서치\n",
    "그리드 서치를 실습할 데이터를 불러옵니다. 이때, k-겹 교차 검증을 사용해 해를 평가할 예정이므로 train_test_split으로 학습 데이터와 평가 데이터로 분리하지는 않았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('../data/classification/optdigits.csv')\n",
    "df2 = pd.read_csv('../data/regression/baseball.csv')\n",
    "X1 = df1.drop('y', axis=1)\n",
    "y1 = df1['y']\n",
    "X2 = df2.drop('y', axis=1)\n",
    "y2 = df2['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSerachCV 클래스 : 주요 인자\n",
    "사이킷런의 model_selection_GridSearchCV 크래스를 이용하면 손쉽게 하이퍼파라미터 튜닝을 위한 그리드 서치를 구현할 수 있습니다. 이 클래스는 주어진 그리드에 속하는 모든 해를 k-겹 교차 검증 방식으로 평가하여 가장 좋은 하이퍼 파라미터를 찾습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요인자\n",
    "- estimator\n",
    "    - 분류 및 회귀 모델 인스턴스\n",
    "- param_grid\n",
    "    - 파라미터 그리드 (사전 자료형)\n",
    "- cv\n",
    "    - 폴드 개수\n",
    "- scoring\n",
    "    - 평가 척도\n",
    "- refit\n",
    "    - 가장 좋은 성능의 하이퍼 파라미터를 갖는 모델을 전체 데이터로 재학습할지 여부"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- param_gird의 키는 estimator의 인자이고 값은 해당 인자가 갖는 값으로 구성된 배열임\n",
    "    - 예시) grid = {\"n_negibors\" : [3, 5, 7], \"metric\" : {\"euclidean\", \"manhattan\"}}\n",
    "- scoring은 각 하이퍼 파라미터를 평가하는 데 사용하는 평가 척도로 'accuracy', 'f1', 'neg_mean_absolute_error' 와 같이 문자열로 입력함. 여기서 neg_mean_absolute_error는 다른 지표처럼 값이 크면 클수록 좋다고 일관되게 평가할 수 있도록 MAE에 마이너스 부호를 붙인 것에 불과함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"n_neighbors\": [3, 5, 7],\n",
    "        \"metric\":[\"euclidean\", \"manhattan\"]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSerachCV 클래스 : 주요 메서드 및 속성\n",
    "\n",
    "주요 메서드 및 속성\n",
    "- fit\n",
    "    - 입력한 그리드 내의 모든 하이퍼 파라미터를 평가\n",
    "- predict\n",
    "    - 가장 우수한 하이퍼 파라미터를 갖는 모델로 예측을 수행\n",
    "- cv_results_\n",
    "    - 그리드 서치를 이용한 탐색 결과\n",
    "- best_estimator_\n",
    "    - 점수가 가장 높은 모델 인스턴스\n",
    "- best_score_\n",
    "    - 최고 점수\n",
    "- best_params_\n",
    "    - 점수가 가장 높은 하이퍼 파라미터"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그리드 서치\n",
    "GridSearchCV를 이용해 k-최근접 이웃(분류)의 하이퍼 파라미터를 튜닝 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 3}</td>\n",
       "      <td>0.982918</td>\n",
       "      <td>0.018591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 5}</td>\n",
       "      <td>0.982562</td>\n",
       "      <td>0.014191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 7}</td>\n",
       "      <td>0.983452</td>\n",
       "      <td>0.017390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 3}</td>\n",
       "      <td>0.978470</td>\n",
       "      <td>0.009196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5}</td>\n",
       "      <td>0.978648</td>\n",
       "      <td>0.040776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 7}</td>\n",
       "      <td>0.978292</td>\n",
       "      <td>0.015188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_score  mean_fit_time\n",
       "0  {'metric': 'euclidean', 'n_neighbors': 3}         0.982918       0.018591\n",
       "1  {'metric': 'euclidean', 'n_neighbors': 5}         0.982562       0.014191\n",
       "2  {'metric': 'euclidean', 'n_neighbors': 7}         0.983452       0.017390\n",
       "3  {'metric': 'manhattan', 'n_neighbors': 3}         0.978470       0.009196\n",
       "4  {'metric': 'manhattan', 'n_neighbors': 5}         0.978648       0.040776\n",
       "5  {'metric': 'manhattan', 'n_neighbors': 7}         0.978292       0.015188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                    cv=5,\n",
    "                    param_grid=grid,\n",
    "                    scoring=\"accuracy\").fit(X1, y1)\n",
    "result = pd.DataFrame(clf.cv_results_)\n",
    "display(result[['params','mean_test_score','mean_fit_time']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- params: param_gird의 하이퍼 파라미터\n",
    "- mean_test_score : k-겹 교차 검증에서 k번 평가한 결과의 평균값\n",
    "- mean_fit_time : 평균 학습 시간"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV를 이용해 k-최근접 이웃(분류)의 하이퍼 파라미터를 튜닝해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='euclidean', n_neighbors=7)\n",
      "0.9834519572953736\n",
      "{'metric': 'euclidean', 'n_neighbors': 7}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV를 이용해 k-최근접 이웃(회귀)의 하이퍼 파라미터를 튜닝해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 3}</td>\n",
       "      <td>-666.301580</td>\n",
       "      <td>0.010395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 5}</td>\n",
       "      <td>-651.092379</td>\n",
       "      <td>0.005597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 7}</td>\n",
       "      <td>-653.397034</td>\n",
       "      <td>0.004597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 3}</td>\n",
       "      <td>-690.902253</td>\n",
       "      <td>0.007993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 5}</td>\n",
       "      <td>-655.554548</td>\n",
       "      <td>0.010392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 7}</td>\n",
       "      <td>-644.461514</td>\n",
       "      <td>0.009794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_score  mean_fit_time\n",
       "0  {'metric': 'euclidean', 'n_neighbors': 3}      -666.301580       0.010395\n",
       "1  {'metric': 'euclidean', 'n_neighbors': 5}      -651.092379       0.005597\n",
       "2  {'metric': 'euclidean', 'n_neighbors': 7}      -653.397034       0.004597\n",
       "3  {'metric': 'manhattan', 'n_neighbors': 3}      -690.902253       0.007993\n",
       "4  {'metric': 'manhattan', 'n_neighbors': 5}      -655.554548       0.010392\n",
       "5  {'metric': 'manhattan', 'n_neighbors': 7}      -644.461514       0.009794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "clf = GridSearchCV(estimator=KNeighborsRegressor(),\n",
    "                    cv=5,\n",
    "                    param_grid=grid,\n",
    "                    scoring=\"neg_mean_absolute_error\").fit(X2, y2)\n",
    "result = pd.DataFrame(clf.cv_results_)\n",
    "display(result[['params','mean_test_score','mean_fit_time']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neg_mean_absoulte_error는 MAE에 마이너스 부호만 붙인 것임\n",
    "- mean_test_score가 -644.461514로 가장 큰 5번 행의 파라미터가 가장 좋다고 할 수 있음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ParameterGrid를 이용한 그리드 서치\n",
    "## GridSearch의 문제점\n",
    "GridSearchCV 클래스는 사용하기 매우 간편하지만, 학습 데이터로 전처리 모델을 학습하고 전체 데이터에 적용하는 등 적절하게 데이터를 전처리 하기 어렵습니다.\n",
    "\n",
    "예) 재샘플링 절대 불가"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParameterGrid 함수\n",
    "ParameterGrid 함수는 사전 형태의 하이퍼 파라미터 그리드를 입력받아 그리드의 모든 해를 순회하는 이터레이터를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'n_neighbors': 3}\n",
      "{'metric': 'euclidean', 'n_neighbors': 5}\n",
      "{'metric': 'euclidean', 'n_neighbors': 7}\n",
      "{'metric': 'manhattan', 'n_neighbors': 3}\n",
      "{'metric': 'manhattan', 'n_neighbors': 5}\n",
      "{'metric': 'manhattan', 'n_neighbors': 7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "for param in ParameterGrid(grid):\n",
    "    print(param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **kwargs 문법\n",
    "사전 자료형으로 클래스나 함수의 인자를 설정하는데 필요한 파이썬 문법으로 **kwargs가 있습니다.\n",
    "- ParameterGrid 인스턴스를 순회하는 변수 param은 사전 자료형으로 키가 모델 인스턴스의 인자이고 값이 해당 인자의 값임\n",
    "- {\"인자\": \"값\"} 형태로 구성된 사전 자료형에 **를 붙이고 입력하면 대응되는 인자에 해당 값이 입력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {\"metric\": \"euclidean\", \"n_neighbors\": 3}\n",
    "KNeighborsClassifier(**param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParameterGrid 와 KFold를 이용한 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "grid = ParameterGrid(grid)\n",
    "kf = KFold(n_splits=5)\n",
    "best_score = -1\n",
    "for param in grid:\n",
    "    total_score = 0\n",
    "    for train_index, test_index in kf.split(X1):\n",
    "        X1_train = X1.loc[train_index]\n",
    "        X1_test = X1.loc[test_index]\n",
    "        y1_train = y1.loc[train_index]\n",
    "        y1_test = y1.loc[test_index]\n",
    "\n",
    "        model=KNeighborsClassifier(**param).fit(X1_train, y1_train)\n",
    "        y1_pred = model.predict(X1_test)\n",
    "        score = accuracy_score(y1_test, y1_pred)\n",
    "        total_score += score/5\n",
    "    if total_score > best_score:\n",
    "        best_score = total_score\n",
    "        best_parameter = param"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 3: 사전 자료형인 grid를 ParameterGrid를 사용해 변환합니다.\n",
    "- 라인 5: 최고 점수 best_score를 -1로 초기화 합니다. 평가 지표인 정확도는 아무리 작아도 0이므로 -1로 초기화하더라도 무방합니다.\n",
    "- 라인 6~7: grid에 있는 하이퍼 파라미터를 순회하면서 평가 점수 total_score를 0으로 초기화 합니다.\n",
    "- 라인 8~17: KFold 클래스를 사용해 5-겹 교차 검증을 수행합니다. score는 i(i=0,1,2,3,4)번째 폴드로 평가한 정확도이며, total_score에 score/5를 더함으로써 평균 정확도를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'n_neighbors': 7} 0.9830960854092526\n"
     ]
    }
   ],
   "source": [
    "print(best_parameter, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "best_score = np.inf\n",
    "for param in grid:\n",
    "    total_score = 0\n",
    "    for train_index, test_index in kf.split(X2):\n",
    "        X2_train = X2.loc[train_index]\n",
    "        X2_test = X2.loc[test_index]\n",
    "        y2_train = y2.loc[train_index]\n",
    "        y2_test = y2.loc[test_index]\n",
    "\n",
    "        model=KNeighborsClassifier(**param).fit(X2_train, y2_train)\n",
    "        y2_pred = model.predict(X2_test)\n",
    "        score = mean_absolute_error(y2_test, y2_pred)\n",
    "        total_score += score/5\n",
    "    if total_score < best_score:\n",
    "        best_score = total_score\n",
    "        best_parameter = param"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 2: MAE는 작으면 작을수록 좋으므로 best_score를 무한대로 초기화합니다.\n",
    "- 라인 15: 현재 탐색 중인 파라미터의 MAE인 total_score가 지금까지 찾은 최저 MAE인 best_score보다 작다면, best_score와 best_parameter를 업데이트 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'n_neighbors': 3} 801.970237050044\n"
     ]
    }
   ],
   "source": [
    "print(best_parameter, best_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 선택과 하이퍼 파리미터 최적화 문제로 확장\n",
    "모델 선택과 하이퍼 파리미터 최적화 문제로 확장 예시 : 탐색 공간 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "rf_grid = {\n",
    "    \"n_estimators\":[20, 50, 100, 200],\n",
    "    \"max_depth\":[3, 4, 5, 6, 7]\n",
    "}\n",
    "\n",
    "nn_grid = {\n",
    "    \"hidden_layer_sizes\":[(10,10), (20,20),(30,30),(20,20,20,20)],\n",
    "    \"max_iter\":[1000, 10000]\n",
    "}\n",
    "model_parameter_dict = {RFC:ParameterGrid(rf_grid), MLP:ParameterGrid(nn_grid)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 12: RandomForestClassifier 클래스를 키로, rf_grid를 값으로 하는 사전과 MLPClassifier 클래스를 키로, nn_grid를 값으로 하는 사전을 정의합니다. 이때, rf_grid와 nn_grid는 ParameterGrid로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 20} 0.16850533807829182\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 20} 0.33647686832740215\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 20} 0.5033807829181495\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 20} 0.6758007117437723\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 20} 0.8450177935943062\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 50} 0.17313167259786477\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 50} 0.349288256227758\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 50} 0.5193950177935943\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 50} 0.6957295373665481\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 50} 0.8688612099644129\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 100} 0.17829181494661922\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 100} 0.352846975088968\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 100} 0.5268683274021353\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 100} 0.701779359430605\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 100} 0.8775800711743772\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 200} 0.17775800711743772\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 200} 0.351423487544484\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 200} 0.5268683274021353\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 200} 0.7021352313167261\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 3, 'n_estimators': 200} 0.8797153024911033\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 20} 0.17597864768683275\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 20} 0.35551601423487544\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 20} 0.5281138790035587\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 20} 0.7076512455516013\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 20} 0.8855871886120995\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 50} 0.18362989323843418\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 50} 0.3653024911032029\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 50} 0.5476868327402136\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 50} 0.7304270462633453\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 50} 0.909252669039146\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 100} 0.18238434163701067\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 100} 0.36459074733096086\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 100} 0.5459074733096085\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 100} 0.7297153024911032\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 100} 0.9115658362989323\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 200} 0.18362989323843418\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 200} 0.36690391459074734\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 200} 0.550355871886121\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 200} 0.7339857651245552\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 4, 'n_estimators': 200} 0.9165480427046263\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 20} 0.1802491103202847\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 20} 0.36619217081850536\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 20} 0.548576512455516\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 20} 0.7313167259786477\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 20} 0.91423487544484\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 50} 0.18718861209964413\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 50} 0.3720640569395018\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 50} 0.5574733096085409\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 50} 0.7425266903914591\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 50} 0.9270462633451958\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 100} 0.18718861209964413\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 100} 0.3725978647686833\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 100} 0.5596085409252669\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 100} 0.747508896797153\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 100} 0.9336298932384341\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 200} 0.18807829181494662\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 200} 0.3747330960854093\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 200} 0.5640569395017794\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 200} 0.7508896797153025\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 5, 'n_estimators': 200} 0.9355871886120997\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 20} 0.1893238434163701\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 20} 0.3754448398576512\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 20} 0.5622775800711743\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 20} 0.7512455516014235\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 20} 0.9371886120996441\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 50} 0.18967971530249111\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 50} 0.3784697508896797\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 50} 0.5665480427046263\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 50} 0.7578291814946619\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 50} 0.9467971530249111\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 100} 0.19110320284697507\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 100} 0.3806049822064057\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 100} 0.5701067615658363\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 100} 0.7594306049822064\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 100} 0.947864768683274\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 200} 0.19021352313167258\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 200} 0.3806049822064057\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 200} 0.5715302491103202\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 200} 0.7624555160142348\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 6, 'n_estimators': 200} 0.9512455516014233\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 20} 0.1919928825622776\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 20} 0.3818505338078292\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 20} 0.5741992882562278\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 20} 0.7624555160142349\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 20} 0.9505338078291815\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 50} 0.1916370106761566\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 50} 0.3845195729537367\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 50} 0.5754448398576513\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 50} 0.7670818505338078\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 50} 0.9558718861209965\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 100} 0.19217081850533807\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 100} 0.3845195729537366\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 100} 0.5772241992882562\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 100} 0.7695729537366548\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 100} 0.9596085409252669\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 200} 0.1916370106761566\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 200} 0.3836298932384342\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 200} 0.5763345195729538\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 200} 0.7676156583629894\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> {'max_depth': 7, 'n_estimators': 200} 0.9576512455516015\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 1000} 0.19270462633451957\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 1000} 0.38434163701067614\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 1000} 0.5788256227758006\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 1000} 0.7711743772241992\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 1000} 0.9583629893238433\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 10000} 0.19128113879003558\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 10000} 0.38416370106761566\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 10000} 0.5752669039145908\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 10000} 0.7674377224199289\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (10, 10), 'max_iter': 10000} 0.9537366548042705\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 1000} 0.19519572953736655\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 1000} 0.3898576512455516\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 1000} 0.5845195729537367\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 1000} 0.7765124555160143\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 1000} 0.9681494661921709\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 10000} 0.19555160142348754\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 10000} 0.3898576512455516\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 10000} 0.5848754448398576\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 10000} 0.7749110320284698\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20), 'max_iter': 10000} 0.9672597864768684\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 1000} 0.19412811387900356\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 1000} 0.3896797153024911\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 1000} 0.5859430604982206\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 1000} 0.7788256227758007\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 1000} 0.9709964412811387\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 10000} 0.19537366548042706\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 10000} 0.3907473309608541\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 10000} 0.5855871886120997\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 10000} 0.7793594306049823\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 10000} 0.9722419928825623\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 1000} 0.19448398576512455\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 1000} 0.3895017793594306\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 1000} 0.5841637010676156\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 1000} 0.7756227758007117\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 1000} 0.9681494661921708\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 10000} 0.19341637010676155\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 10000} 0.3884341637010676\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 10000} 0.5836298932384342\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 10000} 0.7774021352313167\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (20, 20, 20, 20), 'max_iter': 10000} 0.9677935943060498\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "best_score = -1\n",
    "for model_class in model_parameter_dict.keys():\n",
    "    parameter_grid = model_parameter_dict[model_class]\n",
    "    for param in parameter_grid:\n",
    "        total_score = 0\n",
    "        for train_index, test_index in kf.split(X1):\n",
    "            # print(model_class, param)\n",
    "            X1_train = X1.loc[train_index] \n",
    "            X1_test = X1.loc[test_index]\n",
    "            y1_train = y1.loc[train_index]\n",
    "            y1_test = y1.loc[test_index]\n",
    "            model = model_class(**param).fit(X1_train, y1_train)\n",
    "            y1_pred = model.predict(X1_test)\n",
    "            score = accuracy_score(y1_test, y1_pred)\n",
    "            total_score += score / 5\n",
    "            print(model_class, param, total_score)\n",
    "        if total_score > best_score:\n",
    "            best_score = total_score\n",
    "            best_parameter = param\n",
    "            best_model = model_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 라인 3~4: model_parameter_dict의 키를 model_class로 순회하면서 parameter_grid를 정의합니다. model_class가 RFC라면 parameter_grid는 rf_grid가 되먀, MLP라면 nn_grid가 됩니다.\n",
    "- 라인 5~19: 하이퍼파라미터를 튜닝합니다. 모델 클래스가 주어진 상태이므로 이 라인의 코드는 이전에 사용했떤 코드와 같습니다. 단, 모델도 선택해야 하므로 라인 19에서 best_model에 model_class를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'> {'hidden_layer_sizes': (30, 30), 'max_iter': 10000} 0.9722419928825623\n"
     ]
    }
   ],
   "source": [
    "print(best_model, best_parameter, best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "107109ef1f3d2c1d8ef2422d7f3c7553b0305ed5b701a76fbc5bdcb10e21ee2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
